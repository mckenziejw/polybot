{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6728114-828d-45fc-a9cd-f3bfd88cfd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with first 100 markets...\n",
      "\n",
      "================================================================================\n",
      "POLYMARKET ARBITRAGE SCANNER\n",
      "================================================================================\n",
      "Started: 2026-02-19 09:11:24.115302\n",
      "Min liquidity: $50\n",
      "Min profit: 1.0%\n",
      "\n",
      "Fetched 29787 active markets\n",
      "Scanning sample of 100 markets\n",
      "\n",
      "Progress: 50/100 | Found: 0 | Binary checked: 0 | Multi checked: 50 | Errors: 0\n",
      "\n",
      "================================================================================\n",
      "SCAN COMPLETE\n",
      "================================================================================\n",
      "Markets scanned: 100\n",
      "  Binary markets: 0\n",
      "  Multi-outcome markets: 100\n",
      "Opportunities found: 0\n",
      "Errors: 0\n",
      "\n",
      "❌ No arbitrage opportunities found\n"
     ]
    }
   ],
   "source": [
    "# polymarket_arb_scanner.py\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import Dict, List, Optional\n",
    "import json\n",
    "from itertools import combinations\n",
    "\n",
    "class PolymarketArbScanner:\n",
    "    \"\"\"\n",
    "    Scan all Polymarket markets for arbitrage opportunities.\n",
    "    Handles both binary and multi-outcome markets.\n",
    "    \"\"\"\n",
    "    \n",
    "    GAMMA_API = \"https://gamma-api.polymarket.com\"\n",
    "    CLOB_API = \"https://clob.polymarket.com\"\n",
    "    \n",
    "    def __init__(self, min_liquidity: float = 50, min_profit_pct: float = 1.0):\n",
    "        self.min_liquidity = min_liquidity\n",
    "        self.min_profit_pct = min_profit_pct\n",
    "        self.cache_dir = Path(\"data/arb_scanner\")\n",
    "        self.cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def fetch_all_active_markets(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Fetch all active markets from Gamma API.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            all_markets = []\n",
    "            offset = 0\n",
    "            limit = 100\n",
    "            \n",
    "            while True:\n",
    "                resp = requests.get(\n",
    "                    f\"{self.GAMMA_API}/markets\",\n",
    "                    params={\n",
    "                        \"closed\": \"false\",\n",
    "                        \"limit\": limit,\n",
    "                        \"offset\": offset,\n",
    "                    },\n",
    "                    timeout=30\n",
    "                )\n",
    "                resp.raise_for_status()\n",
    "                markets = resp.json()\n",
    "                \n",
    "                if not markets:\n",
    "                    break\n",
    "                \n",
    "                all_markets.extend(markets)\n",
    "                offset += limit\n",
    "                \n",
    "                if len(markets) < limit:\n",
    "                    break\n",
    "                \n",
    "                time.sleep(0.2)\n",
    "            \n",
    "            print(f\"Fetched {len(all_markets)} active markets\")\n",
    "            return all_markets\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching markets: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def fetch_clob_token_book(self, token_id: str) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Fetch order book for a specific CLOB token.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            resp = requests.get(\n",
    "                f\"{self.CLOB_API}/book\",\n",
    "                params={\"token_id\": token_id},\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if resp.status_code != 200:\n",
    "                return None\n",
    "            \n",
    "            book = resp.json()\n",
    "            \n",
    "            bids = book.get('bids', [])\n",
    "            asks = book.get('asks', [])\n",
    "            \n",
    "            if not bids or not asks:\n",
    "                return None\n",
    "            \n",
    "            best_bid_price = float(bids[0]['price'])\n",
    "            best_bid_size = float(bids[0]['size'])\n",
    "            \n",
    "            best_ask_price = float(asks[0]['price'])\n",
    "            best_ask_size = float(asks[0]['size'])\n",
    "            \n",
    "            return {\n",
    "                'token_id': token_id,\n",
    "                'best_bid': best_bid_price,\n",
    "                'best_ask': best_ask_price,\n",
    "                'bid_size': best_bid_size,\n",
    "                'ask_size': best_ask_size,\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    def check_binary_market_arbitrage(self, market: Dict, token_books: List[Dict]) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Check binary market (2 outcomes) for arbitrage.\n",
    "        For binary: sum of asks should be < 1.0\n",
    "        \"\"\"\n",
    "        if len(token_books) != 2:\n",
    "            return None\n",
    "        \n",
    "        book_0, book_1 = token_books[0], token_books[1]\n",
    "        \n",
    "        ask_0 = book_0['best_ask']\n",
    "        ask_1 = book_1['best_ask']\n",
    "        ask_size_0 = book_0['ask_size']\n",
    "        ask_size_1 = book_1['ask_size']\n",
    "        \n",
    "        # Validate prices\n",
    "        if ask_0 <= 0 or ask_0 >= 1 or ask_1 <= 0 or ask_1 >= 1:\n",
    "            return None\n",
    "        \n",
    "        # Combined ask\n",
    "        combined_ask = ask_0 + ask_1\n",
    "        \n",
    "        # Check for arbitrage\n",
    "        if combined_ask >= (1.0 - self.min_profit_pct / 100):\n",
    "            return None\n",
    "        \n",
    "        # Available pairs\n",
    "        available_pairs = min(ask_size_0, ask_size_1)\n",
    "        capital_required = available_pairs * combined_ask\n",
    "        \n",
    "        if capital_required < self.min_liquidity:\n",
    "            return None\n",
    "        \n",
    "        # Calculate profit\n",
    "        profit_per_pair = 1.0 - combined_ask\n",
    "        profit_pct = (profit_per_pair / combined_ask) * 100\n",
    "        total_profit = available_pairs * profit_per_pair\n",
    "        \n",
    "        return {\n",
    "            'type': 'binary',\n",
    "            'tokens': [book_0['token_id'], book_1['token_id']],\n",
    "            'asks': [ask_0, ask_1],\n",
    "            'combined_ask': combined_ask,\n",
    "            'available_pairs': available_pairs,\n",
    "            'capital_required': capital_required,\n",
    "            'profit_per_pair': profit_per_pair,\n",
    "            'profit_pct': profit_pct,\n",
    "            'total_profit': total_profit,\n",
    "        }\n",
    "    \n",
    "    def check_multi_outcome_arbitrage(self, market: Dict, token_books: List[Dict]) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Check multi-outcome market (3+ outcomes) for arbitrage.\n",
    "        For multi-outcome: sum of all asks should be < 1.0\n",
    "        \n",
    "        Strategy: Buy ALL outcome tokens. Exactly one will pay $1, others pay $0.\n",
    "        Cost = sum of all asks\n",
    "        Payout = $1 (guaranteed)\n",
    "        Profit = $1 - sum(asks)\n",
    "        \"\"\"\n",
    "        if len(token_books) < 3:\n",
    "            return None\n",
    "        \n",
    "        # Calculate sum of all asks\n",
    "        asks = [book['best_ask'] for book in token_books]\n",
    "        ask_sizes = [book['ask_size'] for book in token_books]\n",
    "        \n",
    "        # Validate all prices\n",
    "        if any(ask <= 0 or ask >= 1 for ask in asks):\n",
    "            return None\n",
    "        \n",
    "        combined_ask = sum(asks)\n",
    "        \n",
    "        # Check for arbitrage\n",
    "        if combined_ask >= (1.0 - self.min_profit_pct / 100):\n",
    "            return None\n",
    "        \n",
    "        # Available \"sets\" - limited by smallest token\n",
    "        # For multi-outcome, need 1 share of EACH token\n",
    "        available_sets = min(ask_sizes)\n",
    "        capital_required = available_sets * combined_ask\n",
    "        \n",
    "        if capital_required < self.min_liquidity:\n",
    "            return None\n",
    "        \n",
    "        # Calculate profit\n",
    "        profit_per_set = 1.0 - combined_ask\n",
    "        profit_pct = (profit_per_set / combined_ask) * 100\n",
    "        total_profit = available_sets * profit_per_set\n",
    "        \n",
    "        return {\n",
    "            'type': 'multi_outcome',\n",
    "            'num_outcomes': len(token_books),\n",
    "            'tokens': [book['token_id'] for book in token_books],\n",
    "            'asks': asks,\n",
    "            'combined_ask': combined_ask,\n",
    "            'available_sets': available_sets,\n",
    "            'capital_required': capital_required,\n",
    "            'profit_per_set': profit_per_set,\n",
    "            'profit_pct': profit_pct,\n",
    "            'total_profit': total_profit,\n",
    "        }\n",
    "    \n",
    "    def check_market_for_arbitrage(self, market: Dict) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Check any market type for arbitrage opportunities.\n",
    "        Works for binary (2 outcomes) and multi-outcome (3+ outcomes).\n",
    "        \"\"\"\n",
    "        clob_token_ids = market.get('clobTokenIds', [])\n",
    "        \n",
    "        # Need at least 2 outcomes\n",
    "        if len(clob_token_ids) < 2:\n",
    "            return None\n",
    "        \n",
    "        # Fetch all token order books\n",
    "        token_books = []\n",
    "        for token_id in clob_token_ids:\n",
    "            book = self.fetch_clob_token_book(token_id)\n",
    "            if book:\n",
    "                token_books.append(book)\n",
    "            time.sleep(0.05)  # Small delay between token fetches\n",
    "        \n",
    "        # Need all tokens to have books\n",
    "        if len(token_books) != len(clob_token_ids):\n",
    "            return None\n",
    "        \n",
    "        # Check for arbitrage based on market type\n",
    "        if len(token_books) == 2:\n",
    "            arb = self.check_binary_market_arbitrage(market, token_books)\n",
    "        else:\n",
    "            arb = self.check_multi_outcome_arbitrage(market, token_books)\n",
    "        \n",
    "        if not arb:\n",
    "            return None\n",
    "        \n",
    "        # Add market metadata\n",
    "        end_date_iso = market.get('end_date_iso')\n",
    "        if end_date_iso:\n",
    "            try:\n",
    "                end_dt = pd.to_datetime(end_date_iso)\n",
    "                now = pd.Timestamp.now(tz='UTC')\n",
    "                hours_to_resolution = (end_dt - now).total_seconds() / 3600\n",
    "                \n",
    "                if hours_to_resolution < 0:\n",
    "                    return None\n",
    "            except:\n",
    "                hours_to_resolution = None\n",
    "        else:\n",
    "            hours_to_resolution = None\n",
    "        \n",
    "        # Capital efficiency\n",
    "        if hours_to_resolution and hours_to_resolution > 0:\n",
    "            efficiency_score = arb['total_profit'] / hours_to_resolution\n",
    "        else:\n",
    "            efficiency_score = 0\n",
    "        \n",
    "        # Combine arbitrage details with market info\n",
    "        result = {\n",
    "            'market_slug': market.get('slug', ''),\n",
    "            'market_title': market.get('question', '')[:80],\n",
    "            'condition_id': market.get('condition_id', ''),\n",
    "            'market_type': arb['type'],\n",
    "            'num_outcomes': arb.get('num_outcomes', 2),\n",
    "            'hours_to_resolution': hours_to_resolution,\n",
    "            'efficiency_score': efficiency_score,\n",
    "            'end_date': end_date_iso,\n",
    "            **arb  # Merge arbitrage details\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def scan_all_markets(self, sample_size: Optional[int] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Scan all (or sample) markets for arbitrage.\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"POLYMARKET ARBITRAGE SCANNER\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Started: {datetime.now()}\")\n",
    "        print(f\"Min liquidity: ${self.min_liquidity}\")\n",
    "        print(f\"Min profit: {self.min_profit_pct}%\\n\")\n",
    "        \n",
    "        markets = self.fetch_all_active_markets()\n",
    "        \n",
    "        if not markets:\n",
    "            print(\"No markets found\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        if sample_size:\n",
    "            markets = markets[:sample_size]\n",
    "            print(f\"Scanning sample of {len(markets)} markets\\n\")\n",
    "        \n",
    "        opportunities = []\n",
    "        errors = 0\n",
    "        skipped_binary = 0\n",
    "        skipped_multi = 0\n",
    "        \n",
    "        for i, market in enumerate(markets):\n",
    "            if i % 50 == 0 and i > 0:\n",
    "                print(f\"Progress: {i}/{len(markets)} | Found: {len(opportunities)} | \"\n",
    "                      f\"Binary checked: {skipped_binary} | Multi checked: {skipped_multi} | Errors: {errors}\")\n",
    "            \n",
    "            try:\n",
    "                num_outcomes = len(market.get('clobTokenIds', []))\n",
    "                \n",
    "                if num_outcomes == 2:\n",
    "                    skipped_binary += 1\n",
    "                elif num_outcomes > 2:\n",
    "                    skipped_multi += 1\n",
    "                \n",
    "                arb = self.check_market_for_arbitrage(market)\n",
    "                \n",
    "                if arb:\n",
    "                    opportunities.append(arb)\n",
    "                    print(f\"\\n  ✓ ARBITRAGE FOUND!\")\n",
    "                    print(f\"    Market: {arb['market_slug'][:50]}\")\n",
    "                    print(f\"    Type: {arb['market_type']} ({arb['num_outcomes']} outcomes)\")\n",
    "                    print(f\"    Combined ask: {arb['combined_ask']:.4f}\")\n",
    "                    print(f\"    Profit: {arb['profit_pct']:.2f}% (${arb['total_profit']:.2f})\")\n",
    "                    print(f\"    Capital: ${arb['capital_required']:.2f}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                errors += 1\n",
    "                if errors <= 5:\n",
    "                    print(f\"  ✗ Error: {market.get('slug', 'unknown')[:30]}: {str(e)[:50]}\")\n",
    "            \n",
    "            time.sleep(0.15)\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"SCAN COMPLETE\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Markets scanned: {len(markets)}\")\n",
    "        print(f\"  Binary markets: {skipped_binary}\")\n",
    "        print(f\"  Multi-outcome markets: {skipped_multi}\")\n",
    "        print(f\"Opportunities found: {len(opportunities)}\")\n",
    "        print(f\"Errors: {errors}\")\n",
    "        \n",
    "        if not opportunities:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(opportunities)\n",
    "        df = df.sort_values('efficiency_score', ascending=False)\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        output_file = self.cache_dir / f\"scan_{timestamp}.csv\"\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"\\nResults saved: {output_file}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def print_top_opportunities(self, df: pd.DataFrame, top_n: int = 20):\n",
    "        \"\"\"\n",
    "        Print formatted summary of opportunities.\n",
    "        \"\"\"\n",
    "        if df.empty:\n",
    "            print(\"\\n❌ No arbitrage opportunities found\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"TOP {min(top_n, len(df))} OPPORTUNITIES (by capital efficiency)\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        for i, (_, opp) in enumerate(df.head(top_n).iterrows(), 1):\n",
    "            print(f\"{i}. {opp['market_title']}\")\n",
    "            print(f\"   Type: {opp['market_type']} ({opp['num_outcomes']} outcomes)\")\n",
    "            print(f\"   Slug: {opp['market_slug']}\")\n",
    "            print(f\"   Combined Ask: {opp['combined_ask']:.4f}\")\n",
    "            print(f\"   Profit: {opp['profit_pct']:.2f}% (${opp['total_profit']:.2f})\")\n",
    "            print(f\"   Capital: ${opp['capital_required']:.2f}\")\n",
    "            \n",
    "            if pd.notna(opp['hours_to_resolution']):\n",
    "                hours = opp['hours_to_resolution']\n",
    "                if hours < 1:\n",
    "                    print(f\"   Resolves: {hours*60:.0f} min\")\n",
    "                elif hours < 24:\n",
    "                    print(f\"   Resolves: {hours:.1f} hr\")\n",
    "                else:\n",
    "                    print(f\"   Resolves: {hours/24:.1f} days\")\n",
    "                print(f\"   Efficiency: ${opp['efficiency_score']:.2f}/hr\")\n",
    "            print()\n",
    "        \n",
    "        # Summary\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"SUMMARY\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Total opportunities: {len(df)}\")\n",
    "        print(f\"  Binary: {len(df[df['market_type'] == 'binary'])}\")\n",
    "        print(f\"  Multi-outcome: {len(df[df['market_type'] == 'multi_outcome'])}\")\n",
    "        print(f\"\\nTotal profit potential: ${df['total_profit'].sum():.2f}\")\n",
    "        print(f\"Total capital needed: ${df['capital_required'].sum():.2f}\")\n",
    "        print(f\"Weighted avg profit: {(df['total_profit'].sum() / df['capital_required'].sum() * 100):.2f}%\")\n",
    "\n",
    "\n",
    "# Run\n",
    "if __name__ == \"__main__\":\n",
    "    scanner = PolymarketArbScanner(\n",
    "        min_liquidity=50,\n",
    "        min_profit_pct=1.0\n",
    "    )\n",
    "    \n",
    "    # Test with sample\n",
    "    print(\"Testing with first 100 markets...\")\n",
    "    results = scanner.scan_all_markets(sample_size=100)\n",
    "    scanner.print_top_opportunities(results, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc7af7c-0cc7-4d30-94f3-b92c28ec4504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing predictive patterns in order book data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'resolutions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 99\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Run pattern analysis\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalyzing predictive patterns in order book data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 99\u001b[0m patterns_df \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_predictive_patterns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m patterns_df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m, in \u001b[0;36manalyze_predictive_patterns\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03mLook for patterns in order book behavior that predict outcomes.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mThe idea: Maybe certain book imbalances or price movements early in the \u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03mwindow predict the final outcome better than the current mid-price.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m slug \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[43mresolutions\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())[:\u001b[38;5;241m100\u001b[39m]:  \u001b[38;5;66;03m# Sample 100 markets\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Load book data\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     book_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/book_snapshots/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mslug\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m book_path\u001b[38;5;241m.\u001b[39mexists():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resolutions' is not defined"
     ]
    }
   ],
   "source": [
    "# Strategy exploration for BTC 5-minute markets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_predictive_patterns():\n",
    "    \"\"\"\n",
    "    Look for patterns in order book behavior that predict outcomes.\n",
    "    The idea: Maybe certain book imbalances or price movements early in the \n",
    "    window predict the final outcome better than the current mid-price.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for slug in list(resolutions.keys())[:100]:  # Sample 100 markets\n",
    "        # Load book data\n",
    "        book_path = Path(f\"data/book_snapshots/{slug}.parquet\")\n",
    "        if not book_path.exists():\n",
    "            continue\n",
    "        \n",
    "        books = pd.read_parquet(book_path)\n",
    "        books['timestamp_dt'] = pd.to_datetime(books['exchange_timestamp'], unit='ms', utc=True)\n",
    "        \n",
    "        # Get outcome\n",
    "        if slug not in resolutions:\n",
    "            continue\n",
    "        \n",
    "        token_outcomes = resolutions[slug]['token_outcomes']\n",
    "        token_ids = list(token_outcomes.keys())\n",
    "        \n",
    "        if len(token_ids) != 2:\n",
    "            continue\n",
    "        \n",
    "        # Identify YES/NO tokens\n",
    "        yes_token = [tid for tid in token_ids if token_outcomes[tid] == 1.0][0]\n",
    "        no_token = [tid for tid in token_ids if token_outcomes[tid] == 0.0][0]\n",
    "        \n",
    "        # Separate by token\n",
    "        yes_books = books[books['asset_id'] == yes_token].sort_values('timestamp_dt')\n",
    "        no_books = books[books['asset_id'] == no_token].sort_values('timestamp_dt')\n",
    "        \n",
    "        if yes_books.empty or no_books.empty:\n",
    "            continue\n",
    "        \n",
    "        # Calculate features at different time windows\n",
    "        for window_end_pct in [0.2, 0.4, 0.6, 0.8]:  # First 20%, 40%, 60%, 80%\n",
    "            cutoff_idx = int(len(yes_books) * window_end_pct)\n",
    "            \n",
    "            if cutoff_idx < 10:\n",
    "                continue\n",
    "            \n",
    "            yes_window = yes_books.iloc[:cutoff_idx]\n",
    "            no_window = no_books.iloc[:cutoff_idx]\n",
    "            \n",
    "            # Feature: Average mid price\n",
    "            yes_mid = ((yes_window['bid_price_1'] + yes_window['ask_price_1']) / 2).mean()\n",
    "            no_mid = ((no_window['bid_price_1'] + no_window['ask_price_1']) / 2).mean()\n",
    "            \n",
    "            # Feature: Order book imbalance (bid size / ask size)\n",
    "            yes_imbalance = (yes_window['bid_size_1'] / yes_window['ask_size_1']).replace([np.inf, -np.inf], np.nan).mean()\n",
    "            no_imbalance = (no_window['bid_size_1'] / no_window['ask_size_1']).replace([np.inf, -np.inf], np.nan).mean()\n",
    "            \n",
    "            # Feature: Spread\n",
    "            yes_spread = (yes_window['ask_price_1'] - yes_window['bid_price_1']).mean()\n",
    "            no_spread = (no_window['ask_price_1'] - no_window['bid_price_1']).mean()\n",
    "            \n",
    "            # Feature: Price volatility\n",
    "            yes_vol = ((yes_window['bid_price_1'] + yes_window['ask_price_1']) / 2).std()\n",
    "            no_vol = ((no_window['bid_price_1'] + no_window['ask_price_1']) / 2).std()\n",
    "            \n",
    "            # Prediction: Which side wins?\n",
    "            prediction = 1 if yes_mid > no_mid else 0\n",
    "            actual = 1  # YES token won (by definition since we filtered)\n",
    "            correct = (prediction == actual)\n",
    "            \n",
    "            results.append({\n",
    "                'slug': slug,\n",
    "                'window_pct': window_end_pct,\n",
    "                'yes_mid': yes_mid,\n",
    "                'no_mid': no_mid,\n",
    "                'yes_imbalance': yes_imbalance,\n",
    "                'no_imbalance': no_imbalance,\n",
    "                'yes_spread': yes_spread,\n",
    "                'no_spread': no_spread,\n",
    "                'yes_vol': yes_vol,\n",
    "                'no_vol': no_vol,\n",
    "                'prediction': prediction,\n",
    "                'actual': actual,\n",
    "                'correct': correct,\n",
    "                'edge': abs(yes_mid - no_mid),\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run pattern analysis\n",
    "print(\"Analyzing predictive patterns in order book data...\")\n",
    "patterns_df = analyze_predictive_patterns()\n",
    "\n",
    "if not patterns_df.empty:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PREDICTIVE PATTERN ANALYSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Accuracy by window\n",
    "    print(f\"\\nPrediction accuracy by time window:\")\n",
    "    for window_pct in sorted(patterns_df['window_pct'].unique()):\n",
    "        window_data = patterns_df[patterns_df['window_pct'] == window_pct]\n",
    "        accuracy = window_data['correct'].mean()\n",
    "        n = len(window_data)\n",
    "        print(f\"  Using first {int(window_pct*100):2d}% of window: {accuracy:5.1%} accuracy (n={n})\")\n",
    "    \n",
    "    # Can we improve by filtering on \"edge\"?\n",
    "    print(f\"\\nAccuracy when YES clearly ahead (edge > 0.10):\")\n",
    "    for window_pct in sorted(patterns_df['window_pct'].unique()):\n",
    "        window_data = patterns_df[\n",
    "            (patterns_df['window_pct'] == window_pct) &\n",
    "            (patterns_df['edge'] > 0.10)\n",
    "        ]\n",
    "        if not window_data.empty:\n",
    "            accuracy = window_data['correct'].mean()\n",
    "            n = len(window_data)\n",
    "            print(f\"  At {int(window_pct*100):2d}% mark: {accuracy:5.1%} accuracy (n={n})\")\n",
    "    \n",
    "    # Order book imbalance signal?\n",
    "    print(f\"\\nDoes order book imbalance predict outcomes?\")\n",
    "    for window_pct in [0.2, 0.4, 0.6]:\n",
    "        window_data = patterns_df[patterns_df['window_pct'] == window_pct].copy()\n",
    "        \n",
    "        # Try different imbalance thresholds\n",
    "        for threshold in [1.2, 1.5, 2.0]:\n",
    "            strong_buy_pressure = window_data[\n",
    "                (window_data['yes_imbalance'] > threshold) &\n",
    "                (window_data['no_imbalance'] < 1/threshold)\n",
    "            ]\n",
    "            \n",
    "            if not strong_buy_pressure.empty:\n",
    "                accuracy = strong_buy_pressure['correct'].mean()\n",
    "                n = len(strong_buy_pressure)\n",
    "                avg_profit = (strong_buy_pressure['yes_mid'] - 0.5).mean()\n",
    "                print(f\"  {int(window_pct*100)}% window, imbalance >{threshold:.1f}x: \"\n",
    "                      f\"{accuracy:.1%} accuracy (n={n}), avg entry {strong_buy_pressure['yes_mid'].mean():.3f}\")\n",
    "\n",
    "\n",
    "# Strategy 2: Mean reversion on extremes\n",
    "def analyze_mean_reversion():\n",
    "    \"\"\"\n",
    "    Check if prices that hit extremes (0.10 or 0.90) tend to revert.\n",
    "    \"\"\"\n",
    "    \n",
    "    reversions = []\n",
    "    \n",
    "    for slug in list(resolutions.keys())[:100]:\n",
    "        book_path = Path(f\"data/book_snapshots/{slug}.parquet\")\n",
    "        if not book_path.exists():\n",
    "            continue\n",
    "        \n",
    "        books = pd.read_parquet(book_path)\n",
    "        books['timestamp_dt'] = pd.to_datetime(books['exchange_timestamp'], unit='ms', utc=True)\n",
    "        \n",
    "        if slug not in resolutions:\n",
    "            continue\n",
    "        \n",
    "        token_outcomes = resolutions[slug]['token_outcomes']\n",
    "        token_ids = list(token_outcomes.keys())\n",
    "        \n",
    "        if len(token_ids) != 2:\n",
    "            continue\n",
    "        \n",
    "        yes_token = [tid for tid in token_ids if token_outcomes[tid] == 1.0]\n",
    "        if not yes_token:\n",
    "            continue\n",
    "        yes_token = yes_token[0]\n",
    "        \n",
    "        yes_books = books[books['asset_id'] == yes_token].sort_values('timestamp_dt')\n",
    "        \n",
    "        if yes_books.empty or len(yes_books) < 20:\n",
    "            continue\n",
    "        \n",
    "        yes_books['mid'] = (yes_books['bid_price_1'] + yes_books['ask_price_1']) / 2\n",
    "        \n",
    "        # Find if price hit extreme in first 80%\n",
    "        cutoff_idx = int(len(yes_books) * 0.8)\n",
    "        early_books = yes_books.iloc[:cutoff_idx]\n",
    "        late_books = yes_books.iloc[cutoff_idx:]\n",
    "        \n",
    "        # Check for extremes\n",
    "        hit_low = (early_books['mid'] < 0.15).any()\n",
    "        hit_high = (early_books['mid'] > 0.85).any()\n",
    "        \n",
    "        if hit_low:\n",
    "            entry_price = early_books[early_books['mid'] < 0.15]['mid'].iloc[0]\n",
    "            exit_price = late_books['mid'].mean() if not late_books.empty else entry_price\n",
    "            outcome = 1.0  # YES won\n",
    "            \n",
    "            # If we bought at extreme low, what happened?\n",
    "            reversions.append({\n",
    "                'slug': slug,\n",
    "                'extreme': 'low',\n",
    "                'entry': entry_price,\n",
    "                'exit': exit_price,\n",
    "                'outcome': outcome,\n",
    "                'profit': outcome - entry_price,\n",
    "            })\n",
    "        \n",
    "        if hit_high:\n",
    "            # Sold YES (bought NO) when YES was expensive\n",
    "            entry_price = early_books[early_books['mid'] > 0.85]['mid'].iloc[0]\n",
    "            exit_price = late_books['mid'].mean() if not late_books.empty else entry_price\n",
    "            outcome = 1.0  # YES won\n",
    "            \n",
    "            # We bet AGAINST YES at high prices\n",
    "            reversions.append({\n",
    "                'slug': slug,\n",
    "                'extreme': 'high',\n",
    "                'entry': entry_price,\n",
    "                'exit': exit_price,\n",
    "                'outcome': outcome,\n",
    "                'profit': entry_price - outcome,  # We bet against, so profit inverted\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(reversions)\n",
    "\n",
    "print(f\"\\n\\n{'='*80}\")\n",
    "print(\"MEAN REVERSION ANALYSIS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "reversion_df = analyze_mean_reversion()\n",
    "\n",
    "if not reversion_df.empty:\n",
    "    print(f\"\\nBuying at extreme lows (<0.15):\")\n",
    "    low_buys = reversion_df[reversion_df['extreme'] == 'low']\n",
    "    if not low_buys.empty:\n",
    "        print(f\"  Opportunities: {len(low_buys)}\")\n",
    "        print(f\"  Avg entry: {low_buys['entry'].mean():.3f}\")\n",
    "        print(f\"  Avg profit: ${low_buys['profit'].mean():.2f}\")\n",
    "        print(f\"  Win rate: {(low_buys['profit'] > 0).mean():.1%}\")\n",
    "        print(f\"  Total P&L: ${low_buys['profit'].sum():.2f}\")\n",
    "    \n",
    "    print(f\"\\nSelling at extreme highs (>0.85):\")\n",
    "    high_sells = reversion_df[reversion_df['extreme'] == 'high']\n",
    "    if not high_sells.empty:\n",
    "        print(f\"  Opportunities: {len(high_sells)}\")\n",
    "        print(f\"  Avg entry: {high_sells['entry'].mean():.3f}\")\n",
    "        print(f\"  Avg profit: ${high_sells['profit'].mean():.2f}\")\n",
    "        print(f\"  Win rate: {(high_sells['profit'] > 0).mean():.1%}\")\n",
    "        print(f\"  Total P&L: ${high_sells['profit'].sum():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0474b13d-719c-46d6-a431-7371a1b53af3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
