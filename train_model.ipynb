{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6c3a8ee-c64d-4f1f-a312-47a010fdaac2",
   "metadata": {},
   "source": [
    "# Polymarket RL Trading Bot — Model Training Architecture\n",
    "\n",
    "## Overview\n",
    "\n",
    "This project trains a reinforcement learning agent to trade 5-minute BTC Up/Down binary markets on Polymarket. The agent observes the live order book for both tokens alongside BTC price features and learns to take directional positions in prediction markets.\n",
    "\n",
    "---\n",
    "\n",
    "## Data Pipeline\n",
    "\n",
    "### Live Ingest (Operational, not used for training)\n",
    "- Subscribes to the Polymarket WebSocket feed\n",
    "- Receives real-time `BookSnapshot` and `TradeEvent` messages\n",
    "- Dumps events onto a Redis stream\n",
    "- A persistence component reads the stream, normalizes to a protobuf schema, and writes to `.parquet` files under `data/book_snapshots/` and `data/trade_events/`\n",
    "- **Token labels in live data: `Yes` / `No`**\n",
    "\n",
    "### Historical Data — Telonex (`telonex_pipeline.py`)\n",
    "- Fetches historical order book snapshots (5-level depth) for all BTC 5-minute markets from the Telonex API\n",
    "- Coverage: **Feb 12–25, 2026** (~3,732 markets)\n",
    "- Raw files downloaded to `datasets/telonex_raw/`, normalized to `data/telonex_book_snapshots/`\n",
    "- Normalization handles: bid sort (ascending → descending), market window filtering (open_ms to open_ms + 300,000ms), filename mapping (asset_id → slug via Gamma API lookup)\n",
    "- **Token labels in Telonex data: `Up` / `Down`**\n",
    "- ⚠️ Schema match against live data has **not been formally validated** column-by-column\n",
    "\n",
    "### BTC Price Data (`telonex_btc_pipeline.py` / `btc_pipeline.py`)\n",
    "- Source: Binance BTC/USDT quotes via Telonex (100ms depth updates)\n",
    "- Resampled to **1-second bars**\n",
    "- Derived features: `log_return`, `ret_5s`, `ret_15s`, `ret_60s`, `rvol_30s`, `rvol_60s`, `rvol_300s`\n",
    "- Output: `data/btc_quotes/btcusdt_quotes.parquet` (1.12M rows, 13 days)\n",
    "\n",
    "### Market Resolutions (`market_analysis.py` — `ResolutionStore`)\n",
    "- Fetches resolution outcomes from Gamma API: `https://gamma-api.polymarket.com/markets/slug/{slug}`\n",
    "- Cached to `data/resolutions.json`\n",
    "- Schema: `{token_id: 1.0}` for winner, `{token_id: 0.0}` for loser\n",
    "- Originally populated for live-capture slugs; **Telonex slug compatibility not yet confirmed**\n",
    "\n",
    "### Chainlink Oracle Data\n",
    "- **Pending.** Would provide the oracle price at each point in time, which is what determines market resolution. Key feature for the CEX-oracle divergence signal.\n",
    "\n",
    "---\n",
    "\n",
    "## Gymnasium Environment (`polymarket_env.py`)\n",
    "\n",
    "### Episode Structure\n",
    "- One episode = one resolved 5-minute market\n",
    "- Steps through the order book at **100ms resampled intervals** (configurable via `RESAMPLE_MS`)\n",
    "- Resampling: last value within each 100ms bar, forward-filled, backward-filled for gaps\n",
    "- Result: **3,000 steps per episode** (uniform across all markets)\n",
    "\n",
    "### Observation Space (61 dimensions)\n",
    "| Group | Dims | Content |\n",
    "|---|---|---|\n",
    "| Yes book | 23 | mid, spread, imbalance, 5× bid (price, size), 5× ask (price, size) |\n",
    "| No book | 23 | same as Yes |\n",
    "| Position state | 6 | yes_position, no_position, yes_avg_cost, no_avg_cost, unrealized_pnl, capital_at_risk_pct |\n",
    "| Time | 1 | time_remaining_pct (1.0 → 0.0) |\n",
    "| BTC features | 8 | mid_norm, log_return, ret_5s, ret_15s, ret_60s, rvol_30s, rvol_60s, rvol_300s |\n",
    "\n",
    "### Action Space — Discrete(6), Maskable\n",
    "| Action | Description |\n",
    "|---|---|\n",
    "| 0 | Hold |\n",
    "| 1 | Buy Yes small ($50) |\n",
    "| 2 | Buy Yes large ($100) |\n",
    "| 3 | Buy No small ($50) |\n",
    "| 4 | Buy No large ($100) |\n",
    "| 5 | Sell (flatten) |\n",
    "\n",
    "**Action masking:** Buy actions masked at max position ($500 = 5% of $10k bankroll). Sell masked when flat. Uses `sb3-contrib` MaskablePPO interface.\n",
    "\n",
    "### Position & Fill Model\n",
    "- Fill model: **mid-price, immediate** (no slippage simulation)\n",
    "- Cannot hold Yes and No simultaneously; buying one side auto-flattens the other at current mid\n",
    "- Min order: $5. Small order: $50. Large order: $100. Max position: $500.\n",
    "- Average cost tracked via weighted average on add\n",
    "\n",
    "### Reward\n",
    "- **Step reward: 0** (no shaping — terminal only)\n",
    "- **Terminal reward: realized PnL** for the episode\n",
    "- ⚠️ Currently: positions held to expiry are settled at **final mid-price** (incorrect)\n",
    "- Should be: settled at **1.0** (winner) or **0.0** (loser) per market resolution\n",
    "\n",
    "---\n",
    "\n",
    "## Prior Analysis\n",
    "\n",
    "### Calibration Analysis\n",
    "- Pulled live-captured book snapshots and trade events\n",
    "- Joined with Gamma API resolutions\n",
    "- Built calibration curves: implied probability vs actual win rate across price buckets and time windows\n",
    "- **Result: No significant edge found** in tail mispricing hypothesis\n",
    "- This prompted the pivot to RL as a framework for learning more complex conditional strategies\n",
    "\n",
    "### Smart Money Observation\n",
    "- Identified high-volume accounts with consistent positive returns\n",
    "- Behavioral pattern: open both sides near 0.50 at market open, gradually build directional position, occasionally load cheap contracts on the losing side near expiry\n",
    "- Interpreted as: continuously updated internal probability estimate, trading spread between their model and market price throughout the full 5-minute window\n",
    "- This behavioral pattern is consistent with an RL-style EV maximization strategy\n",
    "\n",
    "---\n",
    "\n",
    "## Training Setup (Planned)\n",
    "\n",
    "- Algorithm: **MaskablePPO** (`sb3-contrib`)\n",
    "- Framework: **Stable Baselines 3**\n",
    "- Training data: 3,732 Telonex markets (Feb 12–25, 2026)\n",
    "- BTC features joined at 1s granularity aligned to each 100ms step\n",
    "- Reward shaping strategy: **TBD** — terminal-only reward is likely too sparse for efficient learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc94a61-6aa4-48c1-9112-6839c2ce2f10",
   "metadata": {},
   "source": [
    "# Sanity Runthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b5925e-8b01-45ff-8e28-878aaa2fa58e",
   "metadata": {},
   "source": [
    "1. Check live ingest data for schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15b6bb60-a2d4-459a-bd9c-6658975d7c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing slug: btc-updown-5m-1771348500\n",
      "  Live: data/book_snapshots/btc-updown-5m-1771348500.parquet\n",
      "  Hist: data/telonex_book_snapshots/btc-updown-5m-1771348500.parquet\n",
      "\n",
      "============================================================\n",
      "  SCHEMA: LIVE  (data/book_snapshots/btc-updown-5m-1771348500.parquet)\n",
      "============================================================\n",
      "  Rows: 6,775\n",
      "  Columns (50):\n",
      "    exchange_timestamp             int64         sample=np.int64(1771348564459)\n",
      "    received_timestamp             int64         sample=np.int64(1771348564481)\n",
      "    market                         str           sample='0x41d6b8e6aa306f73a9e0d434a1381e38622b60df9cf9d8c9168c1ae04027d282'\n",
      "    asset_id                       str           sample='55555626743217399864863921075568424822842661856294693148174408457001840592314'\n",
      "    mid_price                      float64       sample=np.float64(0.4)\n",
      "    spread                         float64       sample=np.float64(0.019999999999999962)\n",
      "    book_imbalance                 float64       sample=np.float64(-0.09985952722900987)\n",
      "    bid_price_1                    float64       sample=np.float64(0.39)\n",
      "    bid_size_1                     float64       sample=np.float64(152.16)\n",
      "    bid_price_2                    float64       sample=np.float64(0.38)\n",
      "    bid_size_2                     float64       sample=np.float64(115.89)\n",
      "    bid_price_3                    float64       sample=np.float64(0.37)\n",
      "    bid_size_3                     float64       sample=np.float64(90.0)\n",
      "    bid_price_4                    float64       sample=np.float64(0.36)\n",
      "    bid_size_4                     float64       sample=np.float64(508.0)\n",
      "    bid_price_5                    float64       sample=np.float64(0.35)\n",
      "    bid_size_5                     float64       sample=np.float64(685.0)\n",
      "    bid_price_6                    float64       sample=np.float64(0.34)\n",
      "    bid_size_6                     float64       sample=np.float64(656.0)\n",
      "    bid_price_7                    float64       sample=np.float64(0.33)\n",
      "    bid_size_7                     float64       sample=np.float64(562.0)\n",
      "    bid_price_8                    float64       sample=np.float64(0.32)\n",
      "    bid_size_8                     float64       sample=np.float64(637.0)\n",
      "    bid_price_9                    float64       sample=np.float64(0.31)\n",
      "    bid_size_9                     float64       sample=np.float64(533.37)\n",
      "    bid_price_10                   float64       sample=np.float64(0.3)\n",
      "    bid_size_10                    float64       sample=np.float64(639.05)\n",
      "    ask_price_1                    float64       sample=np.float64(0.41)\n",
      "    ask_size_1                     float64       sample=np.float64(228.78)\n",
      "    ask_price_2                    float64       sample=np.float64(0.42)\n",
      "    ask_size_2                     float64       sample=np.float64(446.9)\n",
      "    ask_price_3                    float64       sample=np.float64(0.43)\n",
      "    ask_size_3                     float64       sample=np.float64(729.85)\n",
      "    ask_price_4                    float64       sample=np.float64(0.44)\n",
      "    ask_size_4                     float64       sample=np.float64(817.92)\n",
      "    ask_price_5                    float64       sample=np.float64(0.45)\n",
      "    ask_size_5                     float64       sample=np.float64(740.81)\n",
      "    ask_price_6                    float64       sample=np.float64(0.46)\n",
      "    ask_size_6                     float64       sample=np.float64(692.06)\n",
      "    ask_price_7                    float64       sample=np.float64(0.47)\n",
      "    ask_size_7                     float64       sample=np.float64(508.0)\n",
      "    ask_price_8                    float64       sample=np.float64(0.48)\n",
      "    ask_size_8                     float64       sample=np.float64(538.0)\n",
      "    ask_price_9                    float64       sample=np.float64(0.49)\n",
      "    ask_size_9                     float64       sample=np.float64(444.0)\n",
      "    ask_price_10                   float64       sample=np.float64(0.5)\n",
      "    ask_size_10                    float64       sample=np.float64(448.0)\n",
      "    hash                           str           sample='b20c25b1c17d0eadbc107a24ee21a77a704ff005'\n",
      "    full_bids                      str           sample='[[0.01, 14633.37], [0.02, 5390.0], [0.03, 1671.32], [0.04, 1503.6], [0.05, 2390.0], [0.06, 1952.32], [0.07, 1045.02], [0.08, 585.5], [0.09, 461.0], [0.1, 582.0], [0.11, 367.0], [0.12, 372.32], [0.13, 674.37], [0.14, 263.7], [0.15, 222.01], [0.16, 379.5], [0.17, 191.88], [0.18, 176.0], [0.19, 141.0], [0.2, 307.69], [0.21, 507.0], [0.22, 189.08], [0.23, 150.0], [0.24, 156.66], [0.25, 231.0], [0.26, 236.37], [0.27, 314.25], [0.28, 224.63], [0.29, 214.36], [0.3, 639.05], [0.31, 533.37], [0.32, 637.0], [0.33, 562.0], [0.34, 656.0], [0.35, 685.0], [0.36, 508.0], [0.37, 90.0], [0.38, 115.89], [0.39, 152.16]]'\n",
      "    full_asks                      str           sample='[[0.99, 14957.8], [0.98, 5403.9], [0.97, 1709.65], [0.96, 1508.6], [0.95, 2678.16], [0.94, 1952.32], [0.93, 1052.02], [0.92, 591.39], [0.91, 461.0], [0.9, 582.0], [0.89, 351.09], [0.88, 363.99], [0.87, 613.37], [0.86, 233.7], [0.85, 227.01], [0.84, 359.5], [0.83, 191.88], [0.82, 151.0], [0.81, 357.57], [0.8, 244.28], [0.79, 514.04], [0.78, 189.08], [0.77, 145.0], [0.76, 170.36], [0.75, 246.0], [0.74, 190.76], [0.73, 349.93], [0.72, 240.0], [0.71, 321.08], [0.7, 398.5], [0.69, 321.41], [0.68, 466.12], [0.67, 361.84], [0.66, 413.45], [0.65, 618.0], [0.64, 362.0], [0.63, 339.0], [0.62, 337.0], [0.61, 301.0], [0.6, 281.0], [0.59, 276.0], [0.58, 333.0], [0.57, 282.85], [0.56, 301.0], [0.55, 281.0], [0.54, 424.7], [0.53, 161.0], [0.52, 386.35], [0.51, 283.0], [0.5, 448.0], [0.49, 444.0], [0.48, 538.0], [0.47, 508.0], [0.46, 692.06], [0.45, 740.81], [0.44, 817.92], [0.43, 729.85], [0.42, 446.9], [0.41, 228.78]]'\n",
      "\n",
      "============================================================\n",
      "  SCHEMA: HIST  (data/telonex_book_snapshots/btc-updown-5m-1771348500.parquet)\n",
      "============================================================\n",
      "  Rows: 92,760\n",
      "  Columns (29):\n",
      "    exchange_timestamp             int64         sample=np.int64(1771348500036)\n",
      "    received_timestamp             int64         sample=np.int64(0)\n",
      "    slug                           str           sample='btc-updown-5m-1771348500'\n",
      "    market                         str           sample='0x41d6b8e6aa306f73a9e0d434a1381e38622b60df9cf9d8c9168c1ae04027d282'\n",
      "    asset_id                       str           sample='55555626743217399864863921075568424822842661856294693148174408457001840592314'\n",
      "    token_label                    str           sample='Up'\n",
      "    mid_price                      float64       sample=np.float64(0.525)\n",
      "    spread                         float64       sample=np.float64(0.030000000000000027)\n",
      "    book_imbalance                 float64       sample=np.float64(0.4711808393447284)\n",
      "    bid_price_1                    float64       sample=np.float64(0.51)\n",
      "    bid_size_1                     float64       sample=np.float64(38.58)\n",
      "    bid_price_2                    float64       sample=np.float64(0.5)\n",
      "    bid_size_2                     float64       sample=np.float64(476.43)\n",
      "    bid_price_3                    float64       sample=np.float64(0.49)\n",
      "    bid_size_3                     float64       sample=np.float64(51.0)\n",
      "    bid_price_4                    float64       sample=np.float64(0.48)\n",
      "    bid_size_4                     float64       sample=np.float64(130.0)\n",
      "    bid_price_5                    float64       sample=np.float64(0.47)\n",
      "    bid_size_5                     float64       sample=np.float64(132.0)\n",
      "    ask_price_1                    float64       sample=np.float64(0.54)\n",
      "    ask_size_1                     float64       sample=np.float64(25.7)\n",
      "    ask_price_2                    float64       sample=np.float64(0.55)\n",
      "    ask_size_2                     float64       sample=np.float64(13.0)\n",
      "    ask_price_3                    float64       sample=np.float64(0.56)\n",
      "    ask_size_3                     float64       sample=np.float64(49.74)\n",
      "    ask_price_4                    float64       sample=np.float64(0.57)\n",
      "    ask_size_4                     float64       sample=np.float64(66.19)\n",
      "    ask_price_5                    float64       sample=np.float64(0.58)\n",
      "    ask_size_5                     float64       sample=np.float64(143.0)\n",
      "\n",
      "============================================================\n",
      "  COLUMN DIFF\n",
      "============================================================\n",
      "\n",
      "  Only in LIVE  (23): ['ask_price_10', 'ask_price_6', 'ask_price_7', 'ask_price_8', 'ask_price_9', 'ask_size_10', 'ask_size_6', 'ask_size_7', 'ask_size_8', 'ask_size_9', 'bid_price_10', 'bid_price_6', 'bid_price_7', 'bid_price_8', 'bid_price_9', 'bid_size_10', 'bid_size_6', 'bid_size_7', 'bid_size_8', 'bid_size_9', 'full_asks', 'full_bids', 'hash']\n",
      "  Only in HIST  (2): ['slug', 'token_label']\n",
      "  Shared        (27): ['ask_price_1', 'ask_price_2', 'ask_price_3', 'ask_price_4', 'ask_price_5', 'ask_size_1', 'ask_size_2', 'ask_size_3', 'ask_size_4', 'ask_size_5', 'asset_id', 'bid_price_1', 'bid_price_2', 'bid_price_3', 'bid_price_4', 'bid_price_5', 'bid_size_1', 'bid_size_2', 'bid_size_3', 'bid_size_4', 'bid_size_5', 'book_imbalance', 'exchange_timestamp', 'market', 'mid_price', 'received_timestamp', 'spread']\n",
      "\n",
      "  Dtype mismatches on shared columns:\n",
      "    None — all shared columns have matching dtypes ✓\n",
      "\n",
      "============================================================\n",
      "  TIMESTAMP ALIGNMENT & DELTA ANALYSIS\n",
      "============================================================\n",
      "\n",
      "  Live asset_ids : ['55555626743217399864863921075568424822842661856294693148174408457001840592314', '38891676940017663165008300290782395435833304620382345770354990847002024631743', '79038510146900893042801536893020073541513038918542564759292956448399941052159', '78713742717802462107541602275160920219502878191303291446973007441056688283628']\n",
      "  Hist asset_ids : ['55555626743217399864863921075568424822842661856294693148174408457001840592314', '38891676940017663165008300290782395435833304620382345770354990847002024631743']\n",
      "\n",
      "  Numeric columns being compared (23): ['mid_price', 'spread', 'book_imbalance', 'bid_price_1', 'bid_price_2', 'bid_price_3', 'bid_price_4', 'bid_price_5', 'bid_size_1', 'bid_size_2', 'bid_size_3', 'bid_size_4', 'bid_size_5', 'ask_price_1', 'ask_price_2', 'ask_price_3', 'ask_price_4', 'ask_price_5', 'ask_size_1', 'ask_size_2', 'ask_size_3', 'ask_size_4', 'ask_size_5']\n",
      "\n",
      "  --- Token: Down ---\n",
      "  Live rows for this token : 3,385\n",
      "  Hist rows for this token : 46,380\n",
      "  Common timestamps        : 3,380 (live=3385, hist=46380)\n",
      "\n",
      "  Delta summary (|live - hist|) across 3,380 aligned rows:\n",
      "\n",
      "  Column                       max_delta   mean_delta   nonzero_rows\n",
      "  -----------------------------------------------------------------\n",
      "  mid_price                     0.015000     0.000537            334 ⚠\n",
      "  spread                        0.030000     0.001074            334 ⚠\n",
      "  book_imbalance                0.822457     0.137612          3,259 ⚠\n",
      "  bid_price_1                   0.020000     0.000515            165 ⚠\n",
      "  bid_price_2                   0.020000     0.000500            163 ⚠\n",
      "  bid_price_3                   0.020000     0.000482            157 ⚠\n",
      "  bid_price_4                   0.020000     0.000479            156 ⚠\n",
      "  bid_price_5                   0.020000     0.000479            156 ⚠\n",
      "  bid_size_1                11832.580000    22.395541            164 ⚠\n",
      "  bid_size_2                12122.170000    29.693473            163 ⚠\n",
      "  bid_size_3                14735.240000    13.759618            157 ⚠\n",
      "  bid_size_4                11318.340000    14.238414            155 ⚠\n",
      "  bid_size_5                14741.240000    14.369438            157 ⚠\n",
      "  ask_price_1                   0.030000     0.000559            169 ⚠\n",
      "  ask_price_2                   0.030000     0.000553            169 ⚠\n",
      "  ask_price_3                   0.030000     0.000553            169 ⚠\n",
      "  ask_price_4                   0.030000     0.000553            169 ⚠\n",
      "  ask_price_5                   0.030000     0.000553            169 ⚠\n",
      "  ask_size_1                 2215.480000    10.823178            169 ⚠\n",
      "  ask_size_2                 2057.610000    12.979962            169 ⚠\n",
      "  ask_size_3                 2017.020000    10.174331            168 ⚠\n",
      "  ask_size_4                  513.670000     7.542497            169 ⚠\n",
      "  ask_size_5                  575.810000     5.952068            169 ⚠\n",
      "\n",
      "  Mismatched rows (delta > 0 in any column):\n",
      "  Total mismatched timestamps: 3,261\n",
      "  Showing first 10:\n",
      "\n",
      "    timestamp=1771348564459\n",
      "      mid_price                 live=0.600000  hist=0.595000  delta=0.005000\n",
      "      spread                    live=0.020000  hist=0.010000  delta=0.010000\n",
      "      book_imbalance            live=0.099860  hist=0.544412  delta=0.444553\n",
      "      ask_price_1               live=0.610000  hist=0.600000  delta=0.010000\n",
      "      ask_price_2               live=0.620000  hist=0.610000  delta=0.010000\n",
      "      ask_price_3               live=0.630000  hist=0.620000  delta=0.010000\n",
      "      ask_price_4               live=0.640000  hist=0.630000  delta=0.010000\n",
      "      ask_price_5               live=0.650000  hist=0.640000  delta=0.010000\n",
      "      ask_size_1                live=152.160000  hist=8.380000  delta=143.780000\n",
      "      ask_size_2                live=115.890000  hist=152.160000  delta=36.270000\n",
      "      ask_size_3                live=90.000000  hist=115.890000  delta=25.890000\n",
      "      ask_size_4                live=508.000000  hist=90.000000  delta=418.000000\n",
      "      ask_size_5                live=685.000000  hist=508.000000  delta=177.000000\n",
      "\n",
      "    timestamp=1771348564479\n",
      "      mid_price                 live=0.605000  hist=0.600000  delta=0.005000\n",
      "      spread                    live=0.030000  hist=0.020000  delta=0.010000\n",
      "      book_imbalance            live=0.094416  hist=0.316364  delta=0.221948\n",
      "      ask_price_1               live=0.620000  hist=0.610000  delta=0.010000\n",
      "      ask_price_2               live=0.630000  hist=0.620000  delta=0.010000\n",
      "      ask_price_3               live=0.640000  hist=0.630000  delta=0.010000\n",
      "      ask_price_4               live=0.650000  hist=0.640000  delta=0.010000\n",
      "      ask_price_5               live=0.660000  hist=0.650000  delta=0.010000\n",
      "      ask_size_1                live=104.290000  hist=152.160000  delta=47.870000\n",
      "      ask_size_2                live=90.000000  hist=104.290000  delta=14.290000\n",
      "      ask_size_3                live=508.000000  hist=90.000000  delta=418.000000\n",
      "      ask_size_4                live=685.000000  hist=508.000000  delta=177.000000\n",
      "      ask_size_5                live=656.000000  hist=685.000000  delta=29.000000\n",
      "\n",
      "    timestamp=1771348564533\n",
      "      book_imbalance            live=0.079089  hist=0.261160  delta=0.182072\n",
      "\n",
      "    timestamp=1771348564559\n",
      "      book_imbalance            live=0.069386  hist=0.175108  delta=0.105723\n",
      "\n",
      "    timestamp=1771348564583\n",
      "      book_imbalance            live=0.050720  hist=0.125559  delta=0.074839\n",
      "\n",
      "    timestamp=1771348564642\n",
      "      book_imbalance            live=0.051725  hist=0.282424  delta=0.230699\n",
      "\n",
      "    timestamp=1771348564660\n",
      "      book_imbalance            live=-0.014516  hist=0.096009  delta=0.110524\n",
      "\n",
      "    timestamp=1771348564756\n",
      "      book_imbalance            live=-0.026643  hist=0.060128  delta=0.086771\n",
      "\n",
      "    timestamp=1771348564766\n",
      "      book_imbalance            live=-0.029744  hist=0.050214  delta=0.079958\n",
      "\n",
      "    timestamp=1771348564773\n",
      "      book_imbalance            live=-0.028804  hist=0.053474  delta=0.082278\n",
      "\n",
      "\n",
      "  --- Token: Up ---\n",
      "  Live rows for this token : 3,384\n",
      "  Hist rows for this token : 46,380\n",
      "  Common timestamps        : 3,379 (live=3384, hist=46380)\n",
      "\n",
      "  Delta summary (|live - hist|) across 3,379 aligned rows:\n",
      "\n",
      "  Column                       max_delta   mean_delta   nonzero_rows\n",
      "  -----------------------------------------------------------------\n",
      "  mid_price                     0.495000     0.000969            334 ⚠\n",
      "  spread                        0.990000     0.001938            334 ⚠\n",
      "  book_imbalance                0.822457     0.137605          3,258 ⚠\n",
      "  bid_price_1                   0.030000     0.000559            169 ⚠\n",
      "  bid_price_2                   0.030000     0.000553            169 ⚠\n",
      "  bid_price_3                   0.030000     0.000553            169 ⚠\n",
      "  bid_price_4                   0.030000     0.000553            169 ⚠\n",
      "  bid_price_5                   0.030000     0.000553            169 ⚠\n",
      "  bid_size_1                 2215.480000    10.826381            169 ⚠\n",
      "  bid_size_2                 2057.610000    12.983803            169 ⚠\n",
      "  bid_size_3                 2017.020000    10.177342            168 ⚠\n",
      "  bid_size_4                  513.670000     7.544729            169 ⚠\n",
      "  bid_size_5                  575.810000     5.953830            169 ⚠\n",
      "  ask_price_1                   0.990000     0.001379            165 ⚠\n",
      "  ask_price_2                   0.990000     0.002240            163 ⚠\n",
      "  ask_price_3                   0.990000     0.000772            157 ⚠\n",
      "  ask_price_4                   0.020000     0.000479            156 ⚠\n",
      "  ask_price_5                   0.990000     0.001059            156 ⚠\n",
      "  ask_size_1                11832.580000    22.402169            164 ⚠\n",
      "  ask_size_2                12122.170000    29.702261            163 ⚠\n",
      "  ask_size_3                14735.240000    13.763690            157 ⚠\n",
      "  ask_size_4                11318.340000    14.242628            155 ⚠\n",
      "  ask_size_5                14741.240000    14.373690            157 ⚠\n",
      "\n",
      "  Mismatched rows (delta > 0 in any column):\n",
      "  Total mismatched timestamps: 3,260\n",
      "  Showing first 10:\n",
      "\n",
      "    timestamp=1771348564459\n",
      "      mid_price                 live=0.400000  hist=0.405000  delta=0.005000\n",
      "      spread                    live=0.020000  hist=0.010000  delta=0.010000\n",
      "      book_imbalance            live=-0.099860  hist=-0.544412  delta=0.444553\n",
      "      bid_price_1               live=0.390000  hist=0.400000  delta=0.010000\n",
      "      bid_price_2               live=0.380000  hist=0.390000  delta=0.010000\n",
      "      bid_price_3               live=0.370000  hist=0.380000  delta=0.010000\n",
      "      bid_price_4               live=0.360000  hist=0.370000  delta=0.010000\n",
      "      bid_price_5               live=0.350000  hist=0.360000  delta=0.010000\n",
      "      bid_size_1                live=152.160000  hist=8.380000  delta=143.780000\n",
      "      bid_size_2                live=115.890000  hist=152.160000  delta=36.270000\n",
      "      bid_size_3                live=90.000000  hist=115.890000  delta=25.890000\n",
      "      bid_size_4                live=508.000000  hist=90.000000  delta=418.000000\n",
      "      bid_size_5                live=685.000000  hist=508.000000  delta=177.000000\n",
      "\n",
      "    timestamp=1771348564479\n",
      "      mid_price                 live=0.395000  hist=0.400000  delta=0.005000\n",
      "      spread                    live=0.030000  hist=0.020000  delta=0.010000\n",
      "      book_imbalance            live=-0.094416  hist=-0.316364  delta=0.221948\n",
      "      bid_price_1               live=0.380000  hist=0.390000  delta=0.010000\n",
      "      bid_price_2               live=0.370000  hist=0.380000  delta=0.010000\n",
      "      bid_price_3               live=0.360000  hist=0.370000  delta=0.010000\n",
      "      bid_price_4               live=0.350000  hist=0.360000  delta=0.010000\n",
      "      bid_price_5               live=0.340000  hist=0.350000  delta=0.010000\n",
      "      bid_size_1                live=104.290000  hist=152.160000  delta=47.870000\n",
      "      bid_size_2                live=90.000000  hist=104.290000  delta=14.290000\n",
      "      bid_size_3                live=508.000000  hist=90.000000  delta=418.000000\n",
      "      bid_size_4                live=685.000000  hist=508.000000  delta=177.000000\n",
      "      bid_size_5                live=656.000000  hist=685.000000  delta=29.000000\n",
      "\n",
      "    timestamp=1771348564533\n",
      "      book_imbalance            live=-0.079089  hist=-0.261160  delta=0.182072\n",
      "\n",
      "    timestamp=1771348564559\n",
      "      book_imbalance            live=-0.069386  hist=-0.175108  delta=0.105723\n",
      "\n",
      "    timestamp=1771348564583\n",
      "      book_imbalance            live=-0.050720  hist=-0.125559  delta=0.074839\n",
      "\n",
      "    timestamp=1771348564642\n",
      "      book_imbalance            live=-0.051725  hist=-0.282424  delta=0.230699\n",
      "\n",
      "    timestamp=1771348564660\n",
      "      book_imbalance            live=0.014516  hist=-0.096009  delta=0.110524\n",
      "\n",
      "    timestamp=1771348564756\n",
      "      book_imbalance            live=0.026643  hist=-0.060128  delta=0.086771\n",
      "\n",
      "    timestamp=1771348564766\n",
      "      book_imbalance            live=0.029744  hist=-0.050214  delta=0.079958\n",
      "\n",
      "    timestamp=1771348564773\n",
      "      book_imbalance            live=0.028804  hist=-0.053474  delta=0.082278\n",
      "\n",
      "\n",
      "============================================================\n",
      "  SUMMARY\n",
      "============================================================\n",
      "  Slug           : btc-updown-5m-1771348500\n",
      "  Live columns   : 50\n",
      "  Hist columns   : 29\n",
      "  Only in live   : ['ask_price_10', 'ask_price_6', 'ask_price_7', 'ask_price_8', 'ask_price_9', 'ask_size_10', 'ask_size_6', 'ask_size_7', 'ask_size_8', 'ask_size_9', 'bid_price_10', 'bid_price_6', 'bid_price_7', 'bid_price_8', 'bid_price_9', 'bid_size_10', 'bid_size_6', 'bid_size_7', 'bid_size_8', 'bid_size_9', 'full_asks', 'full_bids', 'hash']\n",
      "  Only in hist   : ['slug', 'token_label']\n",
      "  Dtype clashes  : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Schema comparison: live ingest vs Telonex historical data.\n",
    "\n",
    "Usage:\n",
    "    python schema_comparison.py\n",
    "\n",
    "Paths are configured at the top. The script will auto-select a slug that\n",
    "exists in both directories. Override SLUG to force a specific market.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Config — adjust paths to match your setup\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "LIVE_DIR     = Path(\"data/book_snapshots\")\n",
    "HIST_DIR     = Path(\"data/telonex_book_snapshots\")\n",
    "SLUG         = \"btc-updown-5m-1771348500\"         # Set to e.g. \"btc-updown-5m-1771348200\" to force\n",
    "N_LEVELS     = 5             # Number of book levels to compare (Telonex only has 5)\n",
    "TIMESTAMP_COL = \"exchange_timestamp\"\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Helpers\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def load(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_parquet(path)\n",
    "    df = df.sort_values(TIMESTAMP_COL).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def print_schema(df: pd.DataFrame, label: str):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  SCHEMA: {label}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Rows: {len(df):,}\")\n",
    "    print(f\"  Columns ({len(df.columns)}):\")\n",
    "    for col in df.columns:\n",
    "        print(f\"    {col:<30} {str(df[col].dtype):<12}  \"\n",
    "              f\"sample={repr(df[col].iloc[0]) if len(df) else 'N/A'}\")\n",
    "\n",
    "def find_common_slug() -> str | None:\n",
    "    live_slugs = {p.stem for p in LIVE_DIR.glob(\"btc-updown-5m-*.parquet\")}\n",
    "    hist_slugs = {p.stem for p in HIST_DIR.glob(\"btc-updown-5m-*.parquet\")}\n",
    "    common = live_slugs & hist_slugs\n",
    "    if not common:\n",
    "        return None\n",
    "    return sorted(common)[0]\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Main\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def main():\n",
    "    slug = SLUG or find_common_slug()\n",
    "    if slug is None:\n",
    "        print(\"ERROR: No slug found in both directories.\")\n",
    "        print(f\"  Live slugs in {LIVE_DIR}: {len(list(LIVE_DIR.glob('*.parquet')))}\")\n",
    "        print(f\"  Hist slugs in {HIST_DIR}: {len(list(HIST_DIR.glob('*.parquet')))}\")\n",
    "        return\n",
    "\n",
    "    live_path = LIVE_DIR / f\"{slug}.parquet\"\n",
    "    hist_path = HIST_DIR / f\"{slug}.parquet\"\n",
    "\n",
    "    if not live_path.exists():\n",
    "        print(f\"ERROR: Live file not found: {live_path}\")\n",
    "        return\n",
    "    if not hist_path.exists():\n",
    "        print(f\"ERROR: Historical file not found: {hist_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nComparing slug: {slug}\")\n",
    "    print(f\"  Live: {live_path}\")\n",
    "    print(f\"  Hist: {hist_path}\")\n",
    "\n",
    "    live = load(live_path)\n",
    "    hist = load(hist_path)\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # 1. Schemas\n",
    "    # -----------------------------------------------------------------------\n",
    "    print_schema(live, f\"LIVE  ({live_path})\")\n",
    "    print_schema(hist, f\"HIST  ({hist_path})\")\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # 2. Column-level diff\n",
    "    # -----------------------------------------------------------------------\n",
    "    live_cols = set(live.columns)\n",
    "    hist_cols = set(hist.columns)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"  COLUMN DIFF\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    only_live = live_cols - hist_cols\n",
    "    only_hist = hist_cols - live_cols\n",
    "    shared    = live_cols & hist_cols\n",
    "\n",
    "    print(f\"\\n  Only in LIVE  ({len(only_live)}): {sorted(only_live)}\")\n",
    "    print(f\"  Only in HIST  ({len(only_hist)}): {sorted(only_hist)}\")\n",
    "    print(f\"  Shared        ({len(shared)}): {sorted(shared)}\")\n",
    "\n",
    "    # Check dtype agreement on shared columns\n",
    "    print(f\"\\n  Dtype mismatches on shared columns:\")\n",
    "    mismatched_dtypes = []\n",
    "    for col in sorted(shared):\n",
    "        ld = str(live[col].dtype)\n",
    "        hd = str(hist[col].dtype)\n",
    "        if ld != hd:\n",
    "            mismatched_dtypes.append((col, ld, hd))\n",
    "            print(f\"    {col:<30} live={ld}  hist={hd}\")\n",
    "    if not mismatched_dtypes:\n",
    "        print(\"    None — all shared columns have matching dtypes ✓\")\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # 3. Align on timestamp and token — compare shared numeric columns\n",
    "    # -----------------------------------------------------------------------\n",
    "    # Telonex data has both Up and Down rows in the same file.\n",
    "    # Live data files contain rows for a single asset_id (one token per file).\n",
    "    # We need to split Telonex by token and compare each to the live file.\n",
    "\n",
    "    # Determine which token the live file contains\n",
    "    live_asset_ids = live[\"asset_id\"].unique() if \"asset_id\" in live.columns else []\n",
    "    hist_asset_ids = hist[\"asset_id\"].unique() if \"asset_id\" in hist.columns else []\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"  TIMESTAMP ALIGNMENT & DELTA ANALYSIS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\n  Live asset_ids : {list(live_asset_ids)}\")\n",
    "    print(f\"  Hist asset_ids : {list(hist_asset_ids)}\")\n",
    "\n",
    "    # Determine numeric columns to diff — book levels up to N_LEVELS, plus derived\n",
    "    numeric_cols_to_compare = (\n",
    "        [\"mid_price\", \"spread\", \"book_imbalance\"]\n",
    "        + [f\"bid_price_{i}\" for i in range(1, N_LEVELS + 1)]\n",
    "        + [f\"bid_size_{i}\"  for i in range(1, N_LEVELS + 1)]\n",
    "        + [f\"ask_price_{i}\" for i in range(1, N_LEVELS + 1)]\n",
    "        + [f\"ask_size_{i}\"  for i in range(1, N_LEVELS + 1)]\n",
    "    )\n",
    "    # Keep only columns present in both\n",
    "    numeric_cols_to_compare = [c for c in numeric_cols_to_compare\n",
    "                                if c in live_cols and c in hist_cols]\n",
    "\n",
    "    print(f\"\\n  Numeric columns being compared ({len(numeric_cols_to_compare)}): \"\n",
    "          f\"{numeric_cols_to_compare}\")\n",
    "\n",
    "    # Split Telonex by token label if multi-token\n",
    "    hist_tokens = {}\n",
    "    if \"token_label\" in hist.columns:\n",
    "        for label, group in hist.groupby(\"token_label\"):\n",
    "            hist_tokens[label] = group.reset_index(drop=True)\n",
    "    else:\n",
    "        # No token_label — treat as single group\n",
    "        hist_tokens[\"(all)\"] = hist\n",
    "\n",
    "    # For each hist token, try to find a matching live subset by asset_id\n",
    "    for token_label, hist_token_df in hist_tokens.items():\n",
    "        print(f\"\\n  --- Token: {token_label} ---\")\n",
    "\n",
    "        # Match live rows by asset_id if possible\n",
    "        if \"asset_id\" in hist_token_df.columns and \"asset_id\" in live.columns:\n",
    "            token_asset_ids = hist_token_df[\"asset_id\"].unique()\n",
    "            live_subset = live[live[\"asset_id\"].isin(token_asset_ids)].copy()\n",
    "        else:\n",
    "            live_subset = live.copy()\n",
    "\n",
    "        print(f\"  Live rows for this token : {len(live_subset):,}\")\n",
    "        print(f\"  Hist rows for this token : {len(hist_token_df):,}\")\n",
    "\n",
    "        if live_subset.empty:\n",
    "            print(\"  No matching live rows for this asset_id — skipping delta analysis.\")\n",
    "            continue\n",
    "\n",
    "        # Align on timestamp\n",
    "        live_idx = live_subset.set_index(TIMESTAMP_COL)\n",
    "        hist_idx = hist_token_df.set_index(TIMESTAMP_COL)\n",
    "        common_ts = live_idx.index.intersection(hist_idx.index)\n",
    "\n",
    "        print(f\"  Common timestamps        : {len(common_ts):,} \"\n",
    "              f\"(live={len(live_idx)}, hist={len(hist_idx)})\")\n",
    "\n",
    "        if len(common_ts) == 0:\n",
    "            print(\"  No overlapping timestamps — cannot compute deltas.\")\n",
    "            print(f\"  Live ts range: {live_idx.index.min()} – {live_idx.index.max()}\")\n",
    "            print(f\"  Hist ts range: {hist_idx.index.min()} – {hist_idx.index.max()}\")\n",
    "            continue\n",
    "\n",
    "        live_aligned = live_idx.loc[common_ts, numeric_cols_to_compare]\n",
    "        hist_aligned = hist_idx.loc[common_ts, numeric_cols_to_compare]\n",
    "\n",
    "        # -----------------------------------------------------------------------\n",
    "        # 4. Compute deltas\n",
    "        # -----------------------------------------------------------------------\n",
    "        delta = (live_aligned - hist_aligned).abs()\n",
    "\n",
    "        print(f\"\\n  Delta summary (|live - hist|) across {len(common_ts):,} aligned rows:\")\n",
    "        print(f\"\\n  {'Column':<25} {'max_delta':>12} {'mean_delta':>12} {'nonzero_rows':>14}\")\n",
    "        print(f\"  {'-'*65}\")\n",
    "\n",
    "        any_mismatch = False\n",
    "        for col in numeric_cols_to_compare:\n",
    "            if col not in delta.columns:\n",
    "                continue\n",
    "            col_delta = delta[col].dropna()\n",
    "            max_d  = col_delta.max()\n",
    "            mean_d = col_delta.mean()\n",
    "            nz     = (col_delta > 0).sum()\n",
    "            flag   = \" ⚠\" if nz > 0 else \"\"\n",
    "            if nz > 0:\n",
    "                any_mismatch = True\n",
    "            print(f\"  {col:<25} {max_d:>12.6f} {mean_d:>12.6f} {nz:>14,}{flag}\")\n",
    "\n",
    "        # -----------------------------------------------------------------------\n",
    "        # 5. Show mismatched rows\n",
    "        # -----------------------------------------------------------------------\n",
    "        if any_mismatch:\n",
    "            print(f\"\\n  Mismatched rows (delta > 0 in any column):\")\n",
    "            mismatch_mask = (delta > 0).any(axis=1)\n",
    "            mismatch_ts   = delta[mismatch_mask].index\n",
    "\n",
    "            print(f\"  Total mismatched timestamps: {len(mismatch_ts):,}\")\n",
    "            print(f\"  Showing first 10:\\n\")\n",
    "\n",
    "            for ts in mismatch_ts[:10]:\n",
    "                print(f\"    timestamp={ts}\")\n",
    "                for col in numeric_cols_to_compare:\n",
    "                    lv = live_aligned.loc[ts, col]\n",
    "                    hv = hist_aligned.loc[ts, col]\n",
    "                    d  = abs(lv - hv)\n",
    "                    if d > 0:\n",
    "                        print(f\"      {col:<25} live={lv:.6f}  hist={hv:.6f}  delta={d:.6f}\")\n",
    "                print()\n",
    "        else:\n",
    "            print(f\"\\n  ✓ All {len(common_ts):,} aligned rows match exactly across \"\n",
    "                  f\"{len(numeric_cols_to_compare)} columns.\")\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"  SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Slug           : {slug}\")\n",
    "    print(f\"  Live columns   : {len(live_cols)}\")\n",
    "    print(f\"  Hist columns   : {len(hist_cols)}\")\n",
    "    print(f\"  Only in live   : {sorted(only_live)}\")\n",
    "    print(f\"  Only in hist   : {sorted(only_hist)}\")\n",
    "    print(f\"  Dtype clashes  : {len(mismatched_dtypes)}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43e0326b-dfc7-41fb-81a0-a87e84d51d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIVE — interval between snapshots (ms):\n",
      "count    4395.000000\n",
      "mean       68.245279\n",
      "std       116.302561\n",
      "min         0.000000\n",
      "25%        16.000000\n",
      "50%        33.000000\n",
      "75%        76.000000\n",
      "max      2291.000000\n",
      "Name: exchange_timestamp, dtype: float64\n",
      "\n",
      "HIST — interval between snapshots (ms):\n",
      "count    39169.000000\n",
      "mean         7.655186\n",
      "std         22.448675\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          3.000000\n",
      "75%          6.000000\n",
      "max        944.000000\n",
      "Name: exchange_timestamp, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "slug = \"btc-updown-5m-1771348800\"  # use one of your matching slugs\n",
    "\n",
    "live = pd.read_parquet(f\"data/book_snapshots/{slug}.parquet\")\n",
    "tes = pd.read_parquet(f\"data/trade_events/{slug}.parquet\")\n",
    "hist = pd.read_parquet(f\"data/telonex_book_snapshots/{slug}.parquet\")\n",
    "\n",
    "# Check update intervals\n",
    "live_up = live[live[\"asset_id\"] == live[\"asset_id\"].iloc[0]].sort_values(\"exchange_timestamp\")\n",
    "tes_up = tes[tes[\"asset_id\"] == tes[\"asset_id\"].iloc[0]].sort_values(\"exchange_timestamp\")\n",
    "hist_up = hist[hist[\"token_label\"] == \"Up\"].sort_values(\"exchange_timestamp\")\n",
    "\n",
    "print(\"LIVE — interval between snapshots (ms):\")\n",
    "print(live_up[\"exchange_timestamp\"].diff().describe())\n",
    "\n",
    "print(\"\\nHIST — interval between snapshots (ms):\")\n",
    "print(hist_up[\"exchange_timestamp\"].diff().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec08ceb7-88c9-411c-892b-67c8a65afa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "live_up['date'] = pd.to_datetime(live_up['exchange_timestamp'], unit='ms')\n",
    "tes_up['date'] = pd.to_datetime(hist_up['exchange_timestamp'], unit='ms')\n",
    "hist_up['date'] = pd.to_datetime(hist_up['exchange_timestamp'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16f74539-512f-47a3-8b33-881d3ab1d95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exchange_timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>bid_size_3</th>\n",
       "      <th>bid_price_3</th>\n",
       "      <th>bid_size_2</th>\n",
       "      <th>bid_price_2</th>\n",
       "      <th>bid_size_1</th>\n",
       "      <th>bid_price_1</th>\n",
       "      <th>ask_price_1</th>\n",
       "      <th>ask_size_1</th>\n",
       "      <th>ask_price_2</th>\n",
       "      <th>ask_size_2</th>\n",
       "      <th>ask_price_3</th>\n",
       "      <th>ask_size_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1771348804585</td>\n",
       "      <td>2026-02-17 17:20:04.585</td>\n",
       "      <td>508.46</td>\n",
       "      <td>0.55</td>\n",
       "      <td>412.15</td>\n",
       "      <td>0.56</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>122.99</td>\n",
       "      <td>0.60</td>\n",
       "      <td>237.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1771348804677</td>\n",
       "      <td>2026-02-17 17:20:04.677</td>\n",
       "      <td>509.46</td>\n",
       "      <td>0.55</td>\n",
       "      <td>415.15</td>\n",
       "      <td>0.56</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>118.99</td>\n",
       "      <td>0.60</td>\n",
       "      <td>237.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1771348804701</td>\n",
       "      <td>2026-02-17 17:20:04.701</td>\n",
       "      <td>509.46</td>\n",
       "      <td>0.55</td>\n",
       "      <td>415.15</td>\n",
       "      <td>0.56</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>118.99</td>\n",
       "      <td>0.60</td>\n",
       "      <td>242.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1771348804716</td>\n",
       "      <td>2026-02-17 17:20:04.716</td>\n",
       "      <td>509.46</td>\n",
       "      <td>0.55</td>\n",
       "      <td>415.15</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>22.08</td>\n",
       "      <td>0.59</td>\n",
       "      <td>118.99</td>\n",
       "      <td>0.60</td>\n",
       "      <td>242.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1771348804726</td>\n",
       "      <td>2026-02-17 17:20:04.726</td>\n",
       "      <td>514.46</td>\n",
       "      <td>0.55</td>\n",
       "      <td>415.15</td>\n",
       "      <td>0.56</td>\n",
       "      <td>22.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>16.47</td>\n",
       "      <td>0.59</td>\n",
       "      <td>118.99</td>\n",
       "      <td>0.60</td>\n",
       "      <td>242.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>1771349104057</td>\n",
       "      <td>2026-02-17 17:25:04.057</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>507772.15</td>\n",
       "      <td>0.02</td>\n",
       "      <td>22036.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>443.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8732</th>\n",
       "      <td>1771349104441</td>\n",
       "      <td>2026-02-17 17:25:04.441</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>507767.15</td>\n",
       "      <td>0.02</td>\n",
       "      <td>22036.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>443.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8886</th>\n",
       "      <td>1771349104441</td>\n",
       "      <td>2026-02-17 17:25:04.441</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>507767.15</td>\n",
       "      <td>0.02</td>\n",
       "      <td>22036.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>443.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8734</th>\n",
       "      <td>1771349104523</td>\n",
       "      <td>2026-02-17 17:25:04.523</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>507748.27</td>\n",
       "      <td>0.02</td>\n",
       "      <td>22036.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>443.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8888</th>\n",
       "      <td>1771349104523</td>\n",
       "      <td>2026-02-17 17:25:04.523</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>507748.27</td>\n",
       "      <td>0.02</td>\n",
       "      <td>22036.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>443.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4396 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      exchange_timestamp                    date  bid_size_3  bid_price_3  \\\n",
       "0          1771348804585 2026-02-17 17:20:04.585      508.46         0.55   \n",
       "2          1771348804677 2026-02-17 17:20:04.677      509.46         0.55   \n",
       "4          1771348804701 2026-02-17 17:20:04.701      509.46         0.55   \n",
       "6          1771348804716 2026-02-17 17:20:04.716      509.46         0.55   \n",
       "8          1771348804726 2026-02-17 17:20:04.726      514.46         0.55   \n",
       "...                  ...                     ...         ...          ...   \n",
       "8730       1771349104057 2026-02-17 17:25:04.057        0.00         0.00   \n",
       "8732       1771349104441 2026-02-17 17:25:04.441        0.00         0.00   \n",
       "8886       1771349104441 2026-02-17 17:25:04.441        0.00         0.00   \n",
       "8734       1771349104523 2026-02-17 17:25:04.523        0.00         0.00   \n",
       "8888       1771349104523 2026-02-17 17:25:04.523        0.00         0.00   \n",
       "\n",
       "      bid_size_2  bid_price_2  bid_size_1  bid_price_1  ask_price_1  \\\n",
       "0         412.15         0.56        5.00         0.57         0.58   \n",
       "2         415.15         0.56       15.00         0.57         0.58   \n",
       "4         415.15         0.56       12.00         0.57         0.58   \n",
       "6         415.15         0.56        2.44         0.57         0.58   \n",
       "8         415.15         0.56       22.44         0.57         0.58   \n",
       "...          ...          ...         ...          ...          ...   \n",
       "8730        0.00         0.00        0.00         0.00         0.01   \n",
       "8732        0.00         0.00        0.00         0.00         0.01   \n",
       "8886        0.00         0.00        0.00         0.00         0.01   \n",
       "8734        0.00         0.00        0.00         0.00         0.01   \n",
       "8888        0.00         0.00        0.00         0.00         0.01   \n",
       "\n",
       "      ask_size_1  ask_price_2  ask_size_2  ask_price_3  ask_size_3  \n",
       "0           6.00         0.59      122.99         0.60      237.50  \n",
       "2           6.00         0.59      118.99         0.60      237.50  \n",
       "4           6.00         0.59      118.99         0.60      242.50  \n",
       "6          22.08         0.59      118.99         0.60      242.50  \n",
       "8          16.47         0.59      118.99         0.60      242.50  \n",
       "...          ...          ...         ...          ...         ...  \n",
       "8730   507772.15         0.02    22036.00         0.03      443.91  \n",
       "8732   507767.15         0.02    22036.00         0.03      443.91  \n",
       "8886   507767.15         0.02    22036.00         0.03      443.91  \n",
       "8734   507748.27         0.02    22036.00         0.03      443.91  \n",
       "8888   507748.27         0.02    22036.00         0.03      443.91  \n",
       "\n",
       "[4396 rows x 14 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "live_up[['exchange_timestamp', 'date', 'bid_size_3','bid_price_3','bid_size_2', 'bid_price_2','bid_size_1','bid_price_1', 'ask_price_1','ask_size_1','ask_price_2','ask_size_2','ask_price_3','ask_size_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b8c04749-4e49-4471-9b14-413512c2e6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exchange_timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>bid_size_3</th>\n",
       "      <th>bid_price_3</th>\n",
       "      <th>bid_size_2</th>\n",
       "      <th>bid_price_2</th>\n",
       "      <th>bid_size_1</th>\n",
       "      <th>bid_price_1</th>\n",
       "      <th>ask_price_1</th>\n",
       "      <th>ask_size_1</th>\n",
       "      <th>ask_price_2</th>\n",
       "      <th>ask_size_2</th>\n",
       "      <th>ask_price_3</th>\n",
       "      <th>ask_size_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1771348800080</td>\n",
       "      <td>2026-02-17 17:20:00.080</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>85.23</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>54.21</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1411.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>34.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1771348800104</td>\n",
       "      <td>2026-02-17 17:20:00.104</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>85.23</td>\n",
       "      <td>0.50</td>\n",
       "      <td>85.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>54.21</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1411.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>34.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1771348800330</td>\n",
       "      <td>2026-02-17 17:20:00.330</td>\n",
       "      <td>85.23</td>\n",
       "      <td>0.50</td>\n",
       "      <td>85.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>25.79</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>54.21</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1411.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>34.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1771348800430</td>\n",
       "      <td>2026-02-17 17:20:00.430</td>\n",
       "      <td>85.23</td>\n",
       "      <td>0.50</td>\n",
       "      <td>85.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>15.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1411.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>34.99</td>\n",
       "      <td>0.55</td>\n",
       "      <td>62.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1771348800433</td>\n",
       "      <td>2026-02-17 17:20:00.433</td>\n",
       "      <td>85.23</td>\n",
       "      <td>0.50</td>\n",
       "      <td>85.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>20.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1411.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>34.99</td>\n",
       "      <td>0.55</td>\n",
       "      <td>62.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78331</th>\n",
       "      <td>1771349099532</td>\n",
       "      <td>2026-02-17 17:24:59.532</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>23247.50</td>\n",
       "      <td>0.02</td>\n",
       "      <td>426.37</td>\n",
       "      <td>0.03</td>\n",
       "      <td>283.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78333</th>\n",
       "      <td>1771349099626</td>\n",
       "      <td>2026-02-17 17:24:59.626</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>23497.50</td>\n",
       "      <td>0.02</td>\n",
       "      <td>426.37</td>\n",
       "      <td>0.03</td>\n",
       "      <td>283.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78335</th>\n",
       "      <td>1771349099718</td>\n",
       "      <td>2026-02-17 17:24:59.718</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>38497.50</td>\n",
       "      <td>0.02</td>\n",
       "      <td>426.37</td>\n",
       "      <td>0.03</td>\n",
       "      <td>283.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78336</th>\n",
       "      <td>1771349099893</td>\n",
       "      <td>2026-02-17 17:24:59.893</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>38699.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>426.37</td>\n",
       "      <td>0.03</td>\n",
       "      <td>283.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78339</th>\n",
       "      <td>1771349099926</td>\n",
       "      <td>2026-02-17 17:24:59.926</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>38704.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>426.37</td>\n",
       "      <td>0.03</td>\n",
       "      <td>283.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39170 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       exchange_timestamp                    date  bid_size_3  bid_price_3  \\\n",
       "0           1771348800080 2026-02-17 17:20:00.080       60.00         0.49   \n",
       "3           1771348800104 2026-02-17 17:20:00.104       60.00         0.49   \n",
       "5           1771348800330 2026-02-17 17:20:00.330       85.23         0.50   \n",
       "6           1771348800430 2026-02-17 17:20:00.430       85.23         0.50   \n",
       "8           1771348800433 2026-02-17 17:20:00.433       85.23         0.50   \n",
       "...                   ...                     ...         ...          ...   \n",
       "78331       1771349099532 2026-02-17 17:24:59.532        0.00         0.00   \n",
       "78333       1771349099626 2026-02-17 17:24:59.626        0.00         0.00   \n",
       "78335       1771349099718 2026-02-17 17:24:59.718        0.00         0.00   \n",
       "78336       1771349099893 2026-02-17 17:24:59.893        0.00         0.00   \n",
       "78339       1771349099926 2026-02-17 17:24:59.926        0.00         0.00   \n",
       "\n",
       "       bid_size_2  bid_price_2  bid_size_1  bid_price_1  ask_price_1  \\\n",
       "0           85.23         0.50        5.00         0.51         0.52   \n",
       "3           85.23         0.50       85.00         0.51         0.52   \n",
       "5           85.00         0.51       25.79         0.52         0.52   \n",
       "6           85.00         0.51       15.60         0.52         0.53   \n",
       "8           85.00         0.51       20.60         0.52         0.53   \n",
       "...           ...          ...         ...          ...          ...   \n",
       "78331        0.00         0.00        0.00         0.00         0.01   \n",
       "78333        0.00         0.00        0.00         0.00         0.01   \n",
       "78335        0.00         0.00        0.00         0.00         0.01   \n",
       "78336        0.00         0.00        0.00         0.00         0.01   \n",
       "78339        0.00         0.00        0.00         0.00         0.01   \n",
       "\n",
       "       ask_size_1  ask_price_2  ask_size_2  ask_price_3  ask_size_3  \n",
       "0           54.21         0.53     1411.76         0.54       34.99  \n",
       "3           54.21         0.53     1411.76         0.54       34.99  \n",
       "5           54.21         0.53     1411.76         0.54       34.99  \n",
       "6         1411.76         0.54       34.99         0.55       62.98  \n",
       "8         1411.76         0.54       34.99         0.55       62.98  \n",
       "...           ...          ...         ...          ...         ...  \n",
       "78331    23247.50         0.02      426.37         0.03      283.91  \n",
       "78333    23497.50         0.02      426.37         0.03      283.91  \n",
       "78335    38497.50         0.02      426.37         0.03      283.91  \n",
       "78336    38699.52         0.02      426.37         0.03      283.91  \n",
       "78339    38704.52         0.02      426.37         0.03      283.91  \n",
       "\n",
       "[39170 rows x 14 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_up[['exchange_timestamp', 'date', 'bid_size_3','bid_price_3','bid_size_2', 'bid_price_2','bid_size_1','bid_price_1', 'ask_price_1','ask_size_1','ask_price_2','ask_size_2','ask_price_3','ask_size_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce29dda6-1a14-443d-8d69-2b0570270457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['exchange_timestamp', 'received_timestamp', 'market', 'asset_id',\n",
       "       'side', 'trade_price', 'size', 'best_bid', 'best_ask', 'mid_price',\n",
       "       'spread', 'hash', 'date'],\n",
       "      dtype='str')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a9bfcbfe-f520-45b7-979a-c67afa1a094d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exchange_timestamp</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>side</th>\n",
       "      <th>size</th>\n",
       "      <th>trade_price</th>\n",
       "      <th>best_bid</th>\n",
       "      <th>best_ask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1771348804579</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>BUY</td>\n",
       "      <td>508.46</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1771348804580</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1771348804581</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>122.99</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1771348804583</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>609.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1771348804584</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>BUY</td>\n",
       "      <td>558.73</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1771348804585</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>BUY</td>\n",
       "      <td>370.22</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1771348804586</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>627.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1771348804588</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>614.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1771348804591</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>BUY</td>\n",
       "      <td>285.10</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1771348804593</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>BUY</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1771348804597</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>BUY</td>\n",
       "      <td>476.23</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1771348804601</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>BUY</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1771348804608</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>BUY</td>\n",
       "      <td>557.33</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1771348804609</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>386.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1771348804623</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>128.99</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1771348804624</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>683.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1771348804626</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>BUY</td>\n",
       "      <td>377.91</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1771348804627</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>BUY</td>\n",
       "      <td>396.25</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1771348804628</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>622.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1771348804629</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>BUY</td>\n",
       "      <td>502.46</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1771348804639</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>BUY</td>\n",
       "      <td>358.22</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1771348804641</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1771348804642</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>BUY</td>\n",
       "      <td>417.15</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1771348804644</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>BUY</td>\n",
       "      <td>422.15</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1771348804645</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1771348804646</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>242.50</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1771348804647</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>599.02</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1771348804650</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>688.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1771348804651</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>118.99</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1771348804654</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>621.29</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1771348804655</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>604.02</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1771348804657</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>379.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1771348804658</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>BUY</td>\n",
       "      <td>415.15</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1771348804659</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>626.29</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1771348804661</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>BUY</td>\n",
       "      <td>637.33</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1771348804662</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>249.50</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1771348804663</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>BUY</td>\n",
       "      <td>509.46</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1771348804666</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>237.50</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1771348804668</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>621.29</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1771348804673</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>160.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1771348804677</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1771348804679</td>\n",
       "      <td>1098611300385439941545533652037690501774261256...</td>\n",
       "      <td>SELL</td>\n",
       "      <td>242.50</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    exchange_timestamp                                           asset_id  \\\n",
       "0        1771348804579  1098611300385439941545533652037690501774261256...   \n",
       "3        1771348804580  1098611300385439941545533652037690501774261256...   \n",
       "5        1771348804581  1098611300385439941545533652037690501774261256...   \n",
       "7        1771348804583  1098611300385439941545533652037690501774261256...   \n",
       "8        1771348804584  1098611300385439941545533652037690501774261256...   \n",
       "10       1771348804585  1098611300385439941545533652037690501774261256...   \n",
       "13       1771348804586  1098611300385439941545533652037690501774261256...   \n",
       "15       1771348804588  1098611300385439941545533652037690501774261256...   \n",
       "16       1771348804591  1098611300385439941545533652037690501774261256...   \n",
       "18       1771348804593  1098611300385439941545533652037690501774261256...   \n",
       "20       1771348804597  1098611300385439941545533652037690501774261256...   \n",
       "22       1771348804601  1098611300385439941545533652037690501774261256...   \n",
       "24       1771348804608  1098611300385439941545533652037690501774261256...   \n",
       "27       1771348804609  1098611300385439941545533652037690501774261256...   \n",
       "29       1771348804623  1098611300385439941545533652037690501774261256...   \n",
       "31       1771348804624  1098611300385439941545533652037690501774261256...   \n",
       "32       1771348804626  1098611300385439941545533652037690501774261256...   \n",
       "34       1771348804627  1098611300385439941545533652037690501774261256...   \n",
       "37       1771348804628  1098611300385439941545533652037690501774261256...   \n",
       "38       1771348804629  1098611300385439941545533652037690501774261256...   \n",
       "40       1771348804639  1098611300385439941545533652037690501774261256...   \n",
       "43       1771348804641  1098611300385439941545533652037690501774261256...   \n",
       "44       1771348804642  1098611300385439941545533652037690501774261256...   \n",
       "46       1771348804644  1098611300385439941545533652037690501774261256...   \n",
       "49       1771348804645  1098611300385439941545533652037690501774261256...   \n",
       "51       1771348804646  1098611300385439941545533652037690501774261256...   \n",
       "53       1771348804647  1098611300385439941545533652037690501774261256...   \n",
       "55       1771348804650  1098611300385439941545533652037690501774261256...   \n",
       "57       1771348804651  1098611300385439941545533652037690501774261256...   \n",
       "59       1771348804654  1098611300385439941545533652037690501774261256...   \n",
       "61       1771348804655  1098611300385439941545533652037690501774261256...   \n",
       "63       1771348804657  1098611300385439941545533652037690501774261256...   \n",
       "64       1771348804658  1098611300385439941545533652037690501774261256...   \n",
       "67       1771348804659  1098611300385439941545533652037690501774261256...   \n",
       "68       1771348804661  1098611300385439941545533652037690501774261256...   \n",
       "71       1771348804662  1098611300385439941545533652037690501774261256...   \n",
       "72       1771348804663  1098611300385439941545533652037690501774261256...   \n",
       "75       1771348804666  1098611300385439941545533652037690501774261256...   \n",
       "77       1771348804668  1098611300385439941545533652037690501774261256...   \n",
       "79       1771348804673  1098611300385439941545533652037690501774261256...   \n",
       "81       1771348804677  1098611300385439941545533652037690501774261256...   \n",
       "83       1771348804679  1098611300385439941545533652037690501774261256...   \n",
       "\n",
       "    side    size  trade_price  best_bid  best_ask  \n",
       "0    BUY  508.46         0.55      0.57      0.59  \n",
       "3   SELL    6.00         0.58      0.57      0.58  \n",
       "5   SELL  122.99         0.59      0.57      0.58  \n",
       "7   SELL  609.00         0.62      0.57      0.58  \n",
       "8    BUY  558.73         0.52      0.57      0.58  \n",
       "10   BUY  370.22         0.46      0.57      0.58  \n",
       "13  SELL  627.00         0.64      0.57      0.58  \n",
       "15  SELL  614.00         0.62      0.57      0.58  \n",
       "16   BUY  285.10         0.32      0.57      0.58  \n",
       "18   BUY   10.00         0.57      0.57      0.58  \n",
       "20   BUY  476.23         0.49      0.57      0.58  \n",
       "22   BUY   15.00         0.57      0.57      0.58  \n",
       "24   BUY  557.33         0.52      0.57      0.58  \n",
       "27  SELL  386.00         0.61      0.57      0.58  \n",
       "29  SELL  128.99         0.59      0.57      0.58  \n",
       "31  SELL  683.00         0.64      0.57      0.58  \n",
       "32   BUY  377.91         0.53      0.57      0.58  \n",
       "34   BUY  396.25         0.54      0.57      0.58  \n",
       "37  SELL  622.00         0.65      0.57      0.58  \n",
       "38   BUY  502.46         0.55      0.57      0.58  \n",
       "40   BUY  358.22         0.46      0.57      0.58  \n",
       "43  SELL   11.00         0.58      0.57      0.58  \n",
       "44   BUY  417.15         0.56      0.57      0.58  \n",
       "46   BUY  422.15         0.56      0.57      0.58  \n",
       "49  SELL   16.00         0.58      0.57      0.58  \n",
       "51  SELL  242.50         0.60      0.57      0.58  \n",
       "53  SELL  599.02         0.63      0.57      0.58  \n",
       "55  SELL  688.00         0.64      0.57      0.58  \n",
       "57  SELL  118.99         0.59      0.57      0.58  \n",
       "59  SELL  621.29         0.62      0.57      0.58  \n",
       "61  SELL  604.02         0.63      0.57      0.58  \n",
       "63  SELL  379.00         0.61      0.57      0.58  \n",
       "64   BUY  415.15         0.56      0.57      0.58  \n",
       "67  SELL  626.29         0.62      0.57      0.58  \n",
       "68   BUY  637.33         0.52      0.57      0.58  \n",
       "71  SELL  249.50         0.60      0.57      0.58  \n",
       "72   BUY  509.46         0.55      0.57      0.58  \n",
       "75  SELL  237.50         0.60      0.57      0.58  \n",
       "77  SELL  621.29         0.62      0.57      0.58  \n",
       "79  SELL  160.00         0.73      0.57      0.58  \n",
       "81  SELL    6.00         0.58      0.57      0.58  \n",
       "83  SELL  242.50         0.60      0.57      0.58  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tes_up[['exchange_timestamp', 'asset_id', 'side', 'size','trade_price', 'best_bid','best_ask']].loc[(tes_up['exchange_timestamp'] >= 1771348804579) & (tes_up['exchange_timestamp'] <= 1771348804679)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f61dc203-081e-4176-b787-115c4f264443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    exchange_timestamp  side  trade_price  best_bid  best_ask  mid_price    size\n",
      "1        1771348804580  SELL         0.58      0.57      0.58      0.575    6.00\n",
      "2        1771348804581  SELL         0.59      0.57      0.58      0.575  122.99\n",
      "3        1771348804583  SELL         0.62      0.57      0.58      0.575  609.00\n",
      "4        1771348804584   BUY         0.52      0.57      0.58      0.575  558.73\n",
      "5        1771348804585   BUY         0.46      0.57      0.58      0.575  370.22\n",
      "6        1771348804586  SELL         0.64      0.57      0.58      0.575  627.00\n",
      "7        1771348804588  SELL         0.62      0.57      0.58      0.575  614.00\n",
      "8        1771348804591   BUY         0.32      0.57      0.58      0.575  285.10\n",
      "9        1771348804593   BUY         0.57      0.57      0.58      0.575   10.00\n",
      "10       1771348804597   BUY         0.49      0.57      0.58      0.575  476.23\n",
      "\n",
      "0.46 + 0.54 = 1.0\n",
      "0.64 + 0.36 = 1.0\n"
     ]
    }
   ],
   "source": [
    "slug   = \"btc-updown-5m-1771348800\"\n",
    "trades = pd.read_parquet(f\"data/trade_events/{slug}.parquet\")\n",
    "trades = trades.sort_values(\"exchange_timestamp\").reset_index(drop=True)\n",
    "\n",
    "asset_id = \"109861130038543994154553365203769050177426125683071298510071991418247079830271\"\n",
    "t = trades[trades[\"asset_id\"] == asset_id].reset_index(drop=True)\n",
    "\n",
    "# Show the full sequence around timestamp 1771348804585-1771348804586\n",
    "mask = (t[\"exchange_timestamp\"] >= 1771348804580) & (t[\"exchange_timestamp\"] <= 1771348804600)\n",
    "print(t[mask][[\"exchange_timestamp\", \"side\", \"trade_price\", \n",
    "               \"best_bid\", \"best_ask\", \"mid_price\", \"size\"]].to_string())\n",
    "\n",
    "# Also check: does trade_price + paired_token_price = 1.0 for these rows?\n",
    "# i.e. is the 0.46 actually the Down token price being reported on the Up token row?\n",
    "print(f\"\\n0.46 + 0.54 = {0.46 + 0.54}\")  # paired Down token price from row 10\n",
    "print(f\"0.64 + 0.36 = {0.64 + 0.36}\")  # paired Down token price from row 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "50e90ded-7840-45db-b920-c1b5297b651d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trade events at anomalous timestamps:\n",
      "    exchange_timestamp side  trade_price  best_bid  best_ask\n",
      "10       1771348804585  BUY         0.46      0.57      0.58\n",
      "16       1771348804591  BUY         0.32      0.57      0.58\n",
      "20       1771348804597  BUY         0.49      0.57      0.58\n",
      "\n",
      "Telonex book state at same timestamps:\n",
      "Empty DataFrame\n",
      "Columns: [exchange_timestamp, mid_price, bid_price_1, ask_price_1]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "slug   = \"btc-updown-5m-1771348800\"\n",
    "trades = pd.read_parquet(f\"data/trade_events/{slug}.parquet\")\n",
    "hist   = pd.read_parquet(f\"data/telonex_book_snapshots/{slug}.parquet\")\n",
    "\n",
    "asset_id = \"109861130038543994154553365203769050177426125683071298510071991418247079830271\"\n",
    "\n",
    "# The anomalous timestamps\n",
    "bad_ts = [1771348804585, 1771348804591, 1771348804597]\n",
    "\n",
    "hist_rows = hist[\n",
    "    (hist[\"asset_id\"] == asset_id) & \n",
    "    (hist[\"exchange_timestamp\"].isin(bad_ts))\n",
    "][[\"exchange_timestamp\", \"mid_price\", \"bid_price_1\", \"ask_price_1\"]]\n",
    "\n",
    "trade_rows = trades[\n",
    "    (trades[\"asset_id\"] == asset_id) & \n",
    "    (trades[\"exchange_timestamp\"].isin(bad_ts))\n",
    "][[\"exchange_timestamp\", \"side\", \"trade_price\", \"best_bid\", \"best_ask\"]]\n",
    "\n",
    "print(\"Trade events at anomalous timestamps:\")\n",
    "print(trade_rows.to_string())\n",
    "print(\"\\nTelonex book state at same timestamps:\")\n",
    "print(hist_rows.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7429464a-6b08-4bee-b606-1368eaa9223b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exchange_timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>bid_size_3</th>\n",
       "      <th>bid_price_3</th>\n",
       "      <th>bid_size_2</th>\n",
       "      <th>bid_price_2</th>\n",
       "      <th>bid_size_1</th>\n",
       "      <th>bid_price_1</th>\n",
       "      <th>ask_price_1</th>\n",
       "      <th>ask_size_1</th>\n",
       "      <th>ask_price_2</th>\n",
       "      <th>ask_size_2</th>\n",
       "      <th>ask_price_3</th>\n",
       "      <th>ask_size_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1771348804585</td>\n",
       "      <td>2026-02-17 17:20:04.585</td>\n",
       "      <td>508.46</td>\n",
       "      <td>0.55</td>\n",
       "      <td>412.15</td>\n",
       "      <td>0.56</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>122.99</td>\n",
       "      <td>0.6</td>\n",
       "      <td>237.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1771348804677</td>\n",
       "      <td>2026-02-17 17:20:04.677</td>\n",
       "      <td>509.46</td>\n",
       "      <td>0.55</td>\n",
       "      <td>415.15</td>\n",
       "      <td>0.56</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>118.99</td>\n",
       "      <td>0.6</td>\n",
       "      <td>237.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exchange_timestamp                    date  bid_size_3  bid_price_3  \\\n",
       "0       1771348804585 2026-02-17 17:20:04.585      508.46         0.55   \n",
       "2       1771348804677 2026-02-17 17:20:04.677      509.46         0.55   \n",
       "\n",
       "   bid_size_2  bid_price_2  bid_size_1  bid_price_1  ask_price_1  ask_size_1  \\\n",
       "0      412.15         0.56         5.0         0.57         0.58         6.0   \n",
       "2      415.15         0.56        15.0         0.57         0.58         6.0   \n",
       "\n",
       "   ask_price_2  ask_size_2  ask_price_3  ask_size_3  \n",
       "0         0.59      122.99          0.6       237.5  \n",
       "2         0.59      118.99          0.6       237.5  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "live_up[['exchange_timestamp', 'date', 'bid_size_3','bid_price_3','bid_size_2', 'bid_price_2','bid_size_1','bid_price_1', 'ask_price_1','ask_size_1','ask_price_2','ask_size_2','ask_price_3','ask_size_3']].loc[(live_up['exchange_timestamp'] >= 1771348804579) & (live_up['exchange_timestamp'] <= 1771348804679)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2ffd22f9-7b65-4dfd-8d12-460d0916da88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suspicious fills (>5c from post-fill mid): 58,242\n",
      "    exchange_timestamp                                                                        asset_id  side  trade_price  best_bid  best_ask  mid_price  fill_vs_mid    size\n",
      "8        1771348804584   26853942177931886201757336755289682872943860044150497825685268669651915309817  SELL         0.48      0.42      0.43      0.425        0.055  558.73\n",
      "9        1771348804584  109861130038543994154553365203769050177426125683071298510071991418247079830271   BUY         0.52      0.57      0.58      0.575       -0.055  558.73\n",
      "10       1771348804585   26853942177931886201757336755289682872943860044150497825685268669651915309817  SELL         0.54      0.42      0.43      0.425        0.115  370.22\n",
      "11       1771348804585  109861130038543994154553365203769050177426125683071298510071991418247079830271   BUY         0.46      0.57      0.58      0.575       -0.115  370.22\n",
      "12       1771348804586  109861130038543994154553365203769050177426125683071298510071991418247079830271  SELL         0.64      0.57      0.58      0.575        0.065  627.00\n",
      "13       1771348804586   26853942177931886201757336755289682872943860044150497825685268669651915309817   BUY         0.36      0.42      0.43      0.425       -0.065  627.00\n",
      "16       1771348804591  109861130038543994154553365203769050177426125683071298510071991418247079830271   BUY         0.32      0.57      0.58      0.575       -0.255  285.10\n",
      "17       1771348804591   26853942177931886201757336755289682872943860044150497825685268669651915309817  SELL         0.68      0.42      0.43      0.425        0.255  285.10\n",
      "20       1771348804597   26853942177931886201757336755289682872943860044150497825685268669651915309817  SELL         0.51      0.42      0.43      0.425        0.085  476.23\n",
      "21       1771348804597  109861130038543994154553365203769050177426125683071298510071991418247079830271   BUY         0.49      0.57      0.58      0.575       -0.085  476.23\n",
      "24       1771348804608  109861130038543994154553365203769050177426125683071298510071991418247079830271   BUY         0.52      0.57      0.58      0.575       -0.055  557.33\n",
      "25       1771348804608   26853942177931886201757336755289682872943860044150497825685268669651915309817  SELL         0.48      0.42      0.43      0.425        0.055  557.33\n",
      "30       1771348804624  109861130038543994154553365203769050177426125683071298510071991418247079830271  SELL         0.64      0.57      0.58      0.575        0.065  683.00\n",
      "31       1771348804624   26853942177931886201757336755289682872943860044150497825685268669651915309817   BUY         0.36      0.42      0.43      0.425       -0.065  683.00\n",
      "36       1771348804628  109861130038543994154553365203769050177426125683071298510071991418247079830271  SELL         0.65      0.57      0.58      0.575        0.075  622.00\n",
      "37       1771348804628   26853942177931886201757336755289682872943860044150497825685268669651915309817   BUY         0.35      0.42      0.43      0.425       -0.075  622.00\n",
      "40       1771348804639   26853942177931886201757336755289682872943860044150497825685268669651915309817  SELL         0.54      0.42      0.43      0.425        0.115  358.22\n",
      "41       1771348804639  109861130038543994154553365203769050177426125683071298510071991418247079830271   BUY         0.46      0.57      0.58      0.575       -0.115  358.22\n",
      "52       1771348804647   26853942177931886201757336755289682872943860044150497825685268669651915309817   BUY         0.37      0.42      0.43      0.425       -0.055  599.02\n",
      "53       1771348804647  109861130038543994154553365203769050177426125683071298510071991418247079830271  SELL         0.63      0.57      0.58      0.575        0.055  599.02\n",
      "\n",
      "Rapid reversals (>10c move in <10ms): 84,838\n",
      "    exchange_timestamp  side  trade_price  mid_price  fill_vs_mid    size  ts_diff  price_diff\n",
      "1        1771348804579  SELL         0.45      0.420        0.030  508.46      0.0       -0.10\n",
      "3        1771348804580  SELL         0.58      0.575        0.005    6.00      0.0        0.16\n",
      "4        1771348804581   BUY         0.41      0.425       -0.015  122.99      1.0       -0.17\n",
      "5        1771348804581  SELL         0.59      0.575        0.015  122.99      0.0        0.18\n",
      "7        1771348804583   BUY         0.38      0.425       -0.045  609.00      0.0       -0.24\n",
      "12       1771348804586  SELL         0.64      0.575        0.065  627.00      1.0        0.18\n",
      "13       1771348804586   BUY         0.36      0.425       -0.065  627.00      0.0       -0.28\n",
      "15       1771348804588  SELL         0.62      0.575        0.045  614.00      0.0        0.24\n",
      "16       1771348804591   BUY         0.32      0.575       -0.255  285.10      3.0       -0.30\n",
      "17       1771348804591  SELL         0.68      0.425        0.255  285.10      0.0        0.36\n",
      "18       1771348804593  SELL         0.43      0.425        0.005   10.00      2.0       -0.25\n",
      "19       1771348804593   BUY         0.57      0.575       -0.005   10.00      0.0        0.14\n",
      "23       1771348804601  SELL         0.43      0.425        0.005   15.00      0.0       -0.14\n",
      "27       1771348804609  SELL         0.61      0.575        0.035  386.00      0.0        0.22\n",
      "29       1771348804623  SELL         0.59      0.575        0.015  128.99      0.0        0.18\n",
      "31       1771348804624   BUY         0.36      0.425       -0.065  683.00      0.0       -0.28\n",
      "32       1771348804626   BUY         0.53      0.575       -0.045  377.91      2.0        0.17\n",
      "36       1771348804628  SELL         0.65      0.575        0.075  622.00      1.0        0.19\n",
      "37       1771348804628   BUY         0.35      0.425       -0.075  622.00      0.0       -0.30\n",
      "38       1771348804629   BUY         0.55      0.575       -0.025  502.46      1.0        0.20\n"
     ]
    }
   ],
   "source": [
    "slug   = \"btc-updown-5m-1771348800\"\n",
    "trades = pd.read_parquet(f\"data/trade_events/{slug}.parquet\")\n",
    "trades = trades.sort_values(\"exchange_timestamp\").reset_index(drop=True)\n",
    "\n",
    "# Find the suspicious sequence you're describing\n",
    "# Look for large price deviations from mid\n",
    "trades[\"fill_vs_mid\"] = trades[\"trade_price\"] - trades[\"mid_price\"]\n",
    "\n",
    "# Show rows where fill price deviates more than 5 cents from post-fill mid\n",
    "suspicious = trades[trades[\"fill_vs_mid\"].abs() > 0.05].copy()\n",
    "print(f\"Suspicious fills (>5c from post-fill mid): {len(suspicious):,}\")\n",
    "print(suspicious[[\"exchange_timestamp\", \"asset_id\", \"side\", \"trade_price\", \n",
    "                   \"best_bid\", \"best_ask\", \"mid_price\", \"fill_vs_mid\", \"size\"]].head(20).to_string())\n",
    "\n",
    "# Also show the surrounding context for the specific sequence you saw\n",
    "# Find a sell followed quickly by a buy with large price swings\n",
    "trades[\"ts_diff\"] = trades[\"exchange_timestamp\"].diff()\n",
    "trades[\"price_diff\"] = trades[\"trade_price\"].diff()\n",
    "\n",
    "rapid_reversals = trades[\n",
    "    (trades[\"ts_diff\"] < 10) &           # within 10ms\n",
    "    (trades[\"price_diff\"].abs() > 0.10)  # price moved >10c\n",
    "]\n",
    "print(f\"\\nRapid reversals (>10c move in <10ms): {len(rapid_reversals):,}\")\n",
    "print(rapid_reversals[[\"exchange_timestamp\", \"side\", \"trade_price\", \n",
    "                        \"mid_price\", \"fill_vs_mid\", \"size\", \"ts_diff\", \n",
    "                        \"price_diff\"]].head(20).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4e22669a-4fd7-4a8e-88bc-102592813c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trades     : 139,046\n",
      "Paired matches   : 71,187  (102.4% of rows paired)\n",
      "\n",
      "Price sum (should be ~1.0):\n",
      "count    71187.000000\n",
      "mean         1.000000\n",
      "std          0.025244\n",
      "min          0.400000\n",
      "25%          1.000000\n",
      "50%          1.000000\n",
      "75%          1.000000\n",
      "max          1.600000\n",
      "Name: price_sum, dtype: float64\n",
      "\n",
      "Non-unity price sums (>0.001 from 1.0): 1,192\n"
     ]
    }
   ],
   "source": [
    "slug   = \"btc-updown-5m-1771348800\"\n",
    "trades = pd.read_parquet(f\"data/trade_events/{slug}.parquet\")\n",
    "trades = trades.sort_values([\"exchange_timestamp\", \"size\"]).reset_index(drop=True)\n",
    "\n",
    "# Pair rows by matching timestamp + size across the two asset_ids\n",
    "asset_ids = trades[\"asset_id\"].unique()\n",
    "#assert len(asset_ids) == 2, f\"Expected 2 asset_ids, got {len(asset_ids)}\"\n",
    "\n",
    "t0 = trades[trades[\"asset_id\"] == asset_ids[0]].set_index([\"exchange_timestamp\", \"size\"])\n",
    "t1 = trades[trades[\"asset_id\"] == asset_ids[1]].set_index([\"exchange_timestamp\", \"size\"])\n",
    "\n",
    "paired = t0.join(t1, lsuffix=\"_up\", rsuffix=\"_dn\", how=\"inner\")\n",
    "paired[\"price_sum\"] = paired[\"trade_price_up\"] + paired[\"trade_price_dn\"]\n",
    "\n",
    "print(f\"Total trades     : {len(trades):,}\")\n",
    "print(f\"Paired matches   : {len(paired):,}  ({2*len(paired)/len(trades):.1%} of rows paired)\")\n",
    "print(f\"\\nPrice sum (should be ~1.0):\")\n",
    "print(paired[\"price_sum\"].describe())\n",
    "print(f\"\\nNon-unity price sums (>0.001 from 1.0): \"\n",
    "      f\"{(paired['price_sum'] - 1.0).abs().gt(0.001).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c5788e-2356-495e-9024-12ba7425fd21",
   "metadata": {},
   "source": [
    "## Check to see if Telonex orderbook snapshots are actually interleaving trade events as well. This might account for the order-of-magnitude mismatch in data rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5cca2b1-e0d6-436a-9b02-ec5b935d5b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  Interleave comparison for: btc-updown-5m-1771348800\n",
      "=================================================================\n",
      "\n",
      "  Live book rows  : 8,890\n",
      "  Live trade rows : 139,046\n",
      "  Telonex rows    : 78,340\n",
      "\n",
      "--- Baseline intervals (before interleaving) ---\n",
      "\n",
      "  Live books only — timestamp intervals (ms) for asset_id=109861130038...\n",
      "    count  : 4,395\n",
      "    mean   : 68.25\n",
      "    median : 33.00\n",
      "    std    : 116.30\n",
      "    min    : 0.00\n",
      "    p25    : 16.00\n",
      "    p75    : 76.00\n",
      "    max    : 2291.00\n",
      "\n",
      "  Live trades only — timestamp intervals (ms) for asset_id=109861130038...\n",
      "    count  : 69,242\n",
      "    mean   : 4.33\n",
      "    median : 2.00\n",
      "    std    : 13.30\n",
      "    min    : 0.00\n",
      "    p25    : 1.00\n",
      "    p75    : 3.00\n",
      "    max    : 496.00\n",
      "\n",
      "  Telonex — timestamp intervals (ms) for asset_id=109861130038...\n",
      "    count  : 39,169\n",
      "    mean   : 7.66\n",
      "    median : 3.00\n",
      "    std    : 22.45\n",
      "    min    : 1.00\n",
      "    p25    : 2.00\n",
      "    p75    : 6.00\n",
      "    max    : 944.00\n",
      "\n",
      "--- Building interleaved stream ---\n",
      "  Book rows          : 8,890\n",
      "  Synthetic trade rows: 139,036\n",
      "  Interleaved total  : 147,926\n",
      "  Telonex total      : 78,340\n",
      "  Interleaved / Telonex ratio: 188.83%  (1.0 = perfect match)\n",
      "\n",
      "  Interleaved (books + trades) — timestamp intervals (ms) for asset_id=109861130038...\n",
      "    count  : 73,633\n",
      "    mean   : 4.07\n",
      "    median : 2.00\n",
      "    std    : 12.94\n",
      "    min    : 0.00\n",
      "    p25    : 1.00\n",
      "    p75    : 3.00\n",
      "    max    : 496.00\n",
      "\n",
      "--- Timestamp overlap ---\n",
      "  Interleaved timestamps : 65,040\n",
      "  Telonex timestamps     : 39,170\n",
      "  Common timestamps      : 38,632  (98.6% of Telonex)\n",
      "\n",
      "--- Value deltas at 38,632 common timestamps ---\n",
      "\n",
      "  Column                       max_delta   mean_delta   nonzero_rows\n",
      "  -----------------------------------------------------------------\n",
      "  mid_price                     0.015000     0.000207          5,602 ⚠\n",
      "  spread                        0.030000     0.000413          5,611 ⚠\n",
      "  book_imbalance                0.862551     0.054810         40,569 ⚠\n",
      "  bid_price_1                   0.030000     0.000987          4,347 ⚠\n",
      "  bid_price_2                   0.020000     0.000981          4,410 ⚠\n",
      "  bid_price_3                   0.020000     0.000981          4,408 ⚠\n",
      "  bid_price_4                   0.020000     0.000981          4,408 ⚠\n",
      "  bid_price_5                   0.020000     0.000977          4,393 ⚠\n",
      "  bid_size_1                14983.980000    35.222860         20,325 ⚠\n",
      "  bid_size_2                14984.080000    44.848741         21,677 ⚠\n",
      "  bid_size_3                11191.500000    45.535437         19,692 ⚠\n",
      "  bid_size_4                14908.680000    45.523948         17,434 ⚠\n",
      "  bid_size_5                 3734.180000    43.895823         14,985 ⚠\n",
      "  ask_price_1                   0.040000     0.001060          4,406 ⚠\n",
      "  ask_price_2                   0.030000     0.001065          4,509 ⚠\n",
      "  ask_price_3                   0.030000     0.001073          4,536 ⚠\n",
      "  ask_price_4                   0.030000     0.001075          4,543 ⚠\n",
      "  ask_price_5                   0.030000     0.001076          4,543 ⚠\n",
      "  ask_size_1                16477.020000    42.718762         21,706 ⚠\n",
      "  ask_size_2                 3157.410000    41.932426         22,274 ⚠\n",
      "  ask_size_3                 2555.860000    40.050826         21,149 ⚠\n",
      "  ask_size_4                 2000.000000    32.776702         19,631 ⚠\n",
      "  ask_size_5                  768.370000    27.241369         16,942 ⚠\n",
      "\n",
      "--- Timestamps only in Telonex (not in live + trades) ---\n",
      "  Count: 538  (1.4% of Telonex)\n",
      "  Sample: [1771348800080, 1771348800104, 1771348800330, 1771348800430, 1771348800433]\n",
      "  These timestamps have no corresponding live event.\n",
      "  If this count is high, Telonex has events your feed never received.\n",
      "\n",
      "=================================================================\n",
      "  INTERPRETATION GUIDE\n",
      "=================================================================\n",
      "\n",
      "  Interleaved / Telonex ratio ~1.0\n",
      "      → Hypothesis confirmed. Telonex = books + trades interleaved.\n",
      "        The training/inference gap is manageable.\n",
      "\n",
      "  Ratio << 1.0, low timestamp overlap\n",
      "      → Telonex has events from a different source (e.g. order book diffs,\n",
      "        internal order events). The two feeds are fundamentally different.\n",
      "        Training on Telonex will produce a model that sees a richer world\n",
      "        than live inference can provide.\n",
      "\n",
      "  Ratio ~1.0 but large value deltas\n",
      "      → Row counts match but computed values differ. Check bid sort order,\n",
      "        imbalance computation, or level-depth truncation differences.\n",
      "\n",
      "  Many timestamps only in Telonex\n",
      "      → Telonex received WebSocket messages your ingest missed (drops,\n",
      "        reconnects, latency). Consider this a data quality ceiling on live.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Verify Telonex = live book_snapshots + trade_events interleaved.\n",
    "\n",
    "Logic:\n",
    "  - Load live book_snapshots and trade_events for a matching slug\n",
    "  - For each trade event, reconstruct a synthetic book row by forward-filling\n",
    "    the last known book state, then overwriting mid_price/spread/book_imbalance\n",
    "    with values computed from the trade event's best_bid/best_ask\n",
    "  - Merge synthetic rows with real book snapshot rows, sort by timestamp\n",
    "  - Compare the resulting interleaved stream to Telonex on:\n",
    "      1. Row count / density\n",
    "      2. Timestamp overlap\n",
    "      3. Value deltas at matching timestamps\n",
    "\n",
    "Usage:\n",
    "    python interleave_comparison.py\n",
    "    python interleave_comparison.py --slug btc-updown-5m-1771348200\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Config\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "LIVE_BOOK_DIR  = Path(\"data/book_snapshots\")\n",
    "LIVE_TRADE_DIR = Path(\"data/trade_events\")\n",
    "HIST_DIR       = Path(\"data/telonex_book_snapshots\")\n",
    "TIMESTAMP_COL  = \"exchange_timestamp\"\n",
    "N_LEVELS       = 5   # Telonex only has 5 levels\n",
    "\n",
    "NUMERIC_COLS = (\n",
    "    [\"mid_price\", \"spread\", \"book_imbalance\"]\n",
    "    + [f\"bid_price_{i}\" for i in range(1, N_LEVELS + 1)]\n",
    "    + [f\"bid_size_{i}\"  for i in range(1, N_LEVELS + 1)]\n",
    "    + [f\"ask_price_{i}\" for i in range(1, N_LEVELS + 1)]\n",
    "    + [f\"ask_size_{i}\"  for i in range(1, N_LEVELS + 1)]\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Helpers\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def find_common_slug() -> str | None:\n",
    "    live_slugs = {p.stem for p in LIVE_BOOK_DIR.glob(\"btc-updown-5m-*.parquet\")}\n",
    "    hist_slugs = {p.stem for p in HIST_DIR.glob(\"btc-updown-5m-*.parquet\")}\n",
    "    common = live_slugs & hist_slugs\n",
    "    if not common:\n",
    "        return None\n",
    "    # Prefer a slug that also has a trade_events file\n",
    "    for slug in sorted(common):\n",
    "        if (LIVE_TRADE_DIR / f\"{slug}.parquet\").exists():\n",
    "            return slug\n",
    "    return sorted(common)[0]\n",
    "\n",
    "\n",
    "def load_live_books(slug: str) -> pd.DataFrame:\n",
    "    path = LIVE_BOOK_DIR / f\"{slug}.parquet\"\n",
    "    df = pd.read_parquet(path).sort_values(TIMESTAMP_COL).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_live_trades(slug: str) -> pd.DataFrame | None:\n",
    "    path = LIVE_TRADE_DIR / f\"{slug}.parquet\"\n",
    "    if not path.exists():\n",
    "        print(f\"  WARNING: No trade file found at {path}\")\n",
    "        return None\n",
    "    df = pd.read_parquet(path).sort_values(TIMESTAMP_COL).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_hist(slug: str) -> pd.DataFrame:\n",
    "    path = HIST_DIR / f\"{slug}.parquet\"\n",
    "    df = pd.read_parquet(path).sort_values(TIMESTAMP_COL).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def trades_to_book_rows(trades: pd.DataFrame, books: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each trade event, synthesize a book row by:\n",
    "      1. Forward-filling the last known book snapshot state (bid/ask levels)\n",
    "      2. Overwriting mid_price, spread, book_imbalance from the trade's\n",
    "         best_bid / best_ask fields (which reflect the book state post-trade)\n",
    "\n",
    "    This is the hypothesis: Telonex emits one row per event (book update OR\n",
    "    trade), so interleaving trades into the book stream should approximate it.\n",
    "    \"\"\"\n",
    "    if trades is None or trades.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # We'll build synthetic book rows for each trade event.\n",
    "    # The book level columns come from the last snapshot before the trade.\n",
    "    book_cols = [c for c in NUMERIC_COLS if c in books.columns]\n",
    "\n",
    "    # Index books by timestamp for ffill lookup\n",
    "    books_ts = books.set_index(TIMESTAMP_COL).sort_index()\n",
    "\n",
    "    rows = []\n",
    "    for _, trade in trades.iterrows():\n",
    "        ts        = trade[TIMESTAMP_COL]\n",
    "        asset_id  = trade[\"asset_id\"]\n",
    "\n",
    "        # Find the last book snapshot at or before this timestamp for this asset\n",
    "        asset_books = books_ts[books_ts[\"asset_id\"] == asset_id]\n",
    "        prior = asset_books.loc[:ts]\n",
    "\n",
    "        if prior.empty:\n",
    "            # No prior snapshot — skip this trade (can't reconstruct book state)\n",
    "            continue\n",
    "\n",
    "        last_book = prior.iloc[-1].copy()\n",
    "\n",
    "        # Overwrite derived fields from the trade's reported best bid/ask\n",
    "        best_bid = trade.get(\"best_bid\", np.nan)\n",
    "        best_ask = trade.get(\"best_ask\", np.nan)\n",
    "\n",
    "        if pd.notna(best_bid) and pd.notna(best_ask) and best_bid > 0 and best_ask > 0:\n",
    "            mid   = (best_bid + best_ask) / 2\n",
    "            sprd  = best_ask - best_bid\n",
    "\n",
    "            # Recompute book_imbalance from top-5 levels of the last snapshot,\n",
    "            # using the trade's best_bid/ask to update level 1\n",
    "            bid_sizes = [last_book.get(f\"bid_size_{i}\", 0.0) for i in range(1, N_LEVELS + 1)]\n",
    "            ask_sizes = [last_book.get(f\"ask_size_{i}\", 0.0) for i in range(1, N_LEVELS + 1)]\n",
    "            total_bid = sum(bid_sizes)\n",
    "            total_ask = sum(ask_sizes)\n",
    "            denom     = total_bid + total_ask\n",
    "            imbalance = (total_bid - total_ask) / denom if denom else 0.0\n",
    "        else:\n",
    "            mid       = last_book.get(\"mid_price\", np.nan)\n",
    "            sprd      = last_book.get(\"spread\", np.nan)\n",
    "            imbalance = last_book.get(\"book_imbalance\", np.nan)\n",
    "\n",
    "        row = {\n",
    "            TIMESTAMP_COL:   ts,\n",
    "            \"asset_id\":       asset_id,\n",
    "            \"mid_price\":      mid,\n",
    "            \"spread\":         sprd,\n",
    "            \"book_imbalance\": imbalance,\n",
    "            \"source\":         \"trade\",\n",
    "        }\n",
    "        # Carry forward book levels from last snapshot\n",
    "        for col in book_cols:\n",
    "            if col not in (\"mid_price\", \"spread\", \"book_imbalance\"):\n",
    "                row[col] = last_book.get(col, np.nan)\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def interleave(books: pd.DataFrame, trade_rows: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Merge book snapshots and synthetic trade rows, sort by timestamp.\"\"\"\n",
    "    books_tagged  = books.copy()\n",
    "    books_tagged[\"source\"] = \"book\"\n",
    "\n",
    "    combined = pd.concat([books_tagged, trade_rows], ignore_index=True)\n",
    "    combined = combined.sort_values([TIMESTAMP_COL, \"source\"]).reset_index(drop=True)\n",
    "    return combined\n",
    "\n",
    "\n",
    "def interval_stats(df: pd.DataFrame, asset_id: str, label: str):\n",
    "    sub = df[df[\"asset_id\"] == asset_id].sort_values(TIMESTAMP_COL)\n",
    "    diffs = sub[TIMESTAMP_COL].diff().dropna()\n",
    "    print(f\"\\n  {label} — timestamp intervals (ms) for asset_id={asset_id[:12]}...\")\n",
    "    print(f\"    count  : {len(diffs):,}\")\n",
    "    print(f\"    mean   : {diffs.mean():.2f}\")\n",
    "    print(f\"    median : {diffs.median():.2f}\")\n",
    "    print(f\"    std    : {diffs.std():.2f}\")\n",
    "    print(f\"    min    : {diffs.min():.2f}\")\n",
    "    print(f\"    p25    : {diffs.quantile(0.25):.2f}\")\n",
    "    print(f\"    p75    : {diffs.quantile(0.75):.2f}\")\n",
    "    print(f\"    max    : {diffs.max():.2f}\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Main\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def main(slug: str | None = None):\n",
    "    slug = slug or find_common_slug()\n",
    "    if slug is None:\n",
    "        print(\"ERROR: No slug found in both directories.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n{'='*65}\")\n",
    "    print(f\"  Interleave comparison for: {slug}\")\n",
    "    print(f\"{'='*65}\")\n",
    "\n",
    "    books  = load_live_books(slug)\n",
    "    trades = load_live_trades(slug)\n",
    "    hist   = load_hist(slug)\n",
    "\n",
    "    print(f\"\\n  Live book rows  : {len(books):,}\")\n",
    "    print(f\"  Live trade rows : {len(trades):,}\" if trades is not None else \"  Live trade rows : N/A\")\n",
    "    print(f\"  Telonex rows    : {len(hist):,}\")\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # 1. Baseline interval stats (before interleaving)\n",
    "    # -----------------------------------------------------------------------\n",
    "    # Use the first asset_id seen in live books for all comparisons\n",
    "    live_asset_id = books[\"asset_id\"].iloc[0]\n",
    "    hist_token_df = hist[hist[\"token_label\"] == \"Up\"] if \"token_label\" in hist.columns else hist\n",
    "\n",
    "    print(f\"\\n--- Baseline intervals (before interleaving) ---\")\n",
    "    interval_stats(books,         live_asset_id, \"Live books only\")\n",
    "    if trades is not None:\n",
    "        interval_stats(trades,    live_asset_id, \"Live trades only\")\n",
    "    interval_stats(hist_token_df, hist_token_df[\"asset_id\"].iloc[0] if \"asset_id\" in hist_token_df.columns else \"\", \"Telonex\")\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # 2. Build interleaved stream\n",
    "    # -----------------------------------------------------------------------\n",
    "    print(f\"\\n--- Building interleaved stream ---\")\n",
    "    trade_rows   = trades_to_book_rows(trades, books)\n",
    "    interleaved  = interleave(books, trade_rows)\n",
    "\n",
    "    print(f\"  Book rows          : {len(books):,}\")\n",
    "    print(f\"  Synthetic trade rows: {len(trade_rows):,}\")\n",
    "    print(f\"  Interleaved total  : {len(interleaved):,}\")\n",
    "    print(f\"  Telonex total      : {len(hist):,}\")\n",
    "    ratio = len(interleaved) / len(hist) if len(hist) else 0\n",
    "    print(f\"  Interleaved / Telonex ratio: {ratio:.2%}  (1.0 = perfect match)\")\n",
    "\n",
    "    interval_stats(interleaved, live_asset_id, \"Interleaved (books + trades)\")\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # 3. Timestamp overlap: interleaved vs Telonex\n",
    "    # -----------------------------------------------------------------------\n",
    "    print(f\"\\n--- Timestamp overlap ---\")\n",
    "\n",
    "    interleaved_ts = set(interleaved[interleaved[\"asset_id\"] == live_asset_id][TIMESTAMP_COL])\n",
    "    hist_asset_id  = hist_token_df[\"asset_id\"].iloc[0] if \"asset_id\" in hist_token_df.columns else None\n",
    "    hist_ts        = set(hist_token_df[TIMESTAMP_COL]) if hist_asset_id else set()\n",
    "\n",
    "    common_ts = interleaved_ts & hist_ts\n",
    "    print(f\"  Interleaved timestamps : {len(interleaved_ts):,}\")\n",
    "    print(f\"  Telonex timestamps     : {len(hist_ts):,}\")\n",
    "    print(f\"  Common timestamps      : {len(common_ts):,}  \"\n",
    "          f\"({100*len(common_ts)/max(len(hist_ts),1):.1f}% of Telonex)\")\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # 4. Value deltas at common timestamps\n",
    "    # -----------------------------------------------------------------------\n",
    "    if not common_ts:\n",
    "        print(\"\\n  No common timestamps — cannot compute deltas.\")\n",
    "        print(\"  This confirms the two sources have different event clocks.\")\n",
    "        return\n",
    "\n",
    "    compare_cols = [c for c in NUMERIC_COLS\n",
    "                    if c in interleaved.columns and c in hist_token_df.columns]\n",
    "\n",
    "    inter_aligned = (\n",
    "        interleaved[interleaved[\"asset_id\"] == live_asset_id]\n",
    "        .set_index(TIMESTAMP_COL)\n",
    "        .loc[list(common_ts), compare_cols]\n",
    "        .sort_index()\n",
    "    )\n",
    "    hist_aligned = (\n",
    "        hist_token_df\n",
    "        .set_index(TIMESTAMP_COL)\n",
    "        .loc[list(common_ts), compare_cols]\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    delta = (inter_aligned - hist_aligned).abs()\n",
    "\n",
    "    print(f\"\\n--- Value deltas at {len(common_ts):,} common timestamps ---\")\n",
    "    print(f\"\\n  {'Column':<25} {'max_delta':>12} {'mean_delta':>12} {'nonzero_rows':>14}\")\n",
    "    print(f\"  {'-'*65}\")\n",
    "\n",
    "    for col in compare_cols:\n",
    "        col_delta = delta[col].dropna()\n",
    "        max_d  = col_delta.max()\n",
    "        mean_d = col_delta.mean()\n",
    "        nz     = (col_delta > 0).sum()\n",
    "        flag   = \" ⚠\" if nz > 0 else \"\"\n",
    "        print(f\"  {col:<25} {max_d:>12.6f} {mean_d:>12.6f} {nz:>14,}{flag}\")\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # 5. Timestamps only in Telonex (not in live at all)\n",
    "    # -----------------------------------------------------------------------\n",
    "    only_hist_ts = hist_ts - interleaved_ts\n",
    "    print(f\"\\n--- Timestamps only in Telonex (not in live + trades) ---\")\n",
    "    print(f\"  Count: {len(only_hist_ts):,}  ({100*len(only_hist_ts)/max(len(hist_ts),1):.1f}% of Telonex)\")\n",
    "\n",
    "    if only_hist_ts:\n",
    "        sample_ts = sorted(only_hist_ts)[:5]\n",
    "        print(f\"  Sample: {sample_ts}\")\n",
    "        print(f\"  These timestamps have no corresponding live event.\")\n",
    "        print(f\"  If this count is high, Telonex has events your feed never received.\")\n",
    "\n",
    "    print(f\"\\n{'='*65}\")\n",
    "    print(\"  INTERPRETATION GUIDE\")\n",
    "    print(f\"{'='*65}\")\n",
    "    print(\"\"\"\n",
    "  Interleaved / Telonex ratio ~1.0\n",
    "      → Hypothesis confirmed. Telonex = books + trades interleaved.\n",
    "        The training/inference gap is manageable.\n",
    "\n",
    "  Ratio << 1.0, low timestamp overlap\n",
    "      → Telonex has events from a different source (e.g. order book diffs,\n",
    "        internal order events). The two feeds are fundamentally different.\n",
    "        Training on Telonex will produce a model that sees a richer world\n",
    "        than live inference can provide.\n",
    "\n",
    "  Ratio ~1.0 but large value deltas\n",
    "      → Row counts match but computed values differ. Check bid sort order,\n",
    "        imbalance computation, or level-depth truncation differences.\n",
    "\n",
    "  Many timestamps only in Telonex\n",
    "      → Telonex received WebSocket messages your ingest missed (drops,\n",
    "        reconnects, latency). Consider this a data quality ceiling on live.\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(\"btc-updown-5m-1771348800\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c70c8e9-afa2-4d11-864e-b7754630fac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact timestamp collisions (book + trade same ms): 8,736\n",
      "\n",
      "Nearest-timestamp offset (ms) — Telonex vs live interleaved:\n",
      "count    39170.000000\n",
      "mean        22.554072\n",
      "std        234.420589\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max       4499.000000\n",
      "dtype: float64\n",
      "Within 1ms  : 98.6%\n",
      "Within 5ms  : 98.6%\n",
      "Within 10ms : 98.7%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "slug = \"btc-updown-5m-1771348800\"\n",
    "\n",
    "books  = pd.read_parquet(f\"data/book_snapshots/{slug}.parquet\")\n",
    "trades = pd.read_parquet(f\"data/trade_events/{slug}.parquet\")\n",
    "hist   = pd.read_parquet(f\"data/telonex_book_snapshots/{slug}.parquet\")\n",
    "\n",
    "# --- Test 1: how many exact timestamp collisions exist in live data? ---\n",
    "# (same timestamp, same asset_id appearing in both books and trades)\n",
    "book_ts  = set(zip(books[\"exchange_timestamp\"],  books[\"asset_id\"]))\n",
    "trade_ts = set(zip(trades[\"exchange_timestamp\"], trades[\"asset_id\"]))\n",
    "collisions = book_ts & trade_ts\n",
    "print(f\"Exact timestamp collisions (book + trade same ms): {len(collisions):,}\")\n",
    "# If this is non-trivial (hundreds+), dedup explains the row count difference\n",
    "\n",
    "# --- Test 2: nearest-timestamp match instead of exact ---\n",
    "# For each Telonex timestamp, find the closest interleaved timestamp\n",
    "# and measure the distribution of offsets\n",
    "up_asset = hist[hist[\"token_label\"] == \"Up\"][\"asset_id\"].iloc[0]\n",
    "hist_up  = hist[hist[\"token_label\"] == \"Up\"].sort_values(\"exchange_timestamp\")\n",
    "\n",
    "live_all = pd.concat([\n",
    "    books[books[\"asset_id\"] == up_asset][[\"exchange_timestamp\"]].assign(source=\"book\"),\n",
    "    trades[trades[\"asset_id\"] == up_asset][[\"exchange_timestamp\"]].assign(source=\"trade\"),\n",
    "]).sort_values(\"exchange_timestamp\").reset_index(drop=True)\n",
    "\n",
    "hist_ts_arr  = hist_up[\"exchange_timestamp\"].values\n",
    "live_ts_arr  = live_all[\"exchange_timestamp\"].values\n",
    "\n",
    "# For each hist timestamp, find nearest live timestamp\n",
    "import numpy as np\n",
    "idx     = np.searchsorted(live_ts_arr, hist_ts_arr)\n",
    "idx     = np.clip(idx, 0, len(live_ts_arr) - 1)\n",
    "offsets = np.abs(hist_ts_arr - live_ts_arr[idx])\n",
    "\n",
    "print(f\"\\nNearest-timestamp offset (ms) — Telonex vs live interleaved:\")\n",
    "print(pd.Series(offsets).describe())\n",
    "print(f\"Within 1ms  : {(offsets <= 1).mean():.1%}\")\n",
    "print(f\"Within 5ms  : {(offsets <= 5).mean():.1%}\")\n",
    "print(f\"Within 10ms : {(offsets <= 10).mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a8217cd-57c0-4b9b-8982-0f98b470bec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched   : 38,639  (98.6%)\n",
      "Unmatched : 531  (1.4%)\n",
      "\n",
      "Unmatched rows — position in market window (seconds):\n",
      "count    531.000000\n",
      "mean       3.311881\n",
      "std        9.277767\n",
      "min        0.080000\n",
      "25%        1.795500\n",
      "50%        3.194000\n",
      "75%        3.953000\n",
      "max      215.057000\n",
      "Name: seconds_into_market, dtype: float64\n",
      "\n",
      "Distribution across 30s buckets:\n",
      "seconds_into_market\n",
      "(-0.135, 21.578]      530\n",
      "(193.559, 215.057]      1\n",
      "dtype: int64\n",
      "\n",
      "Unmatched rows — mid_price distribution:\n",
      "count    531.000000\n",
      "mean       0.544266\n",
      "std        0.031439\n",
      "min        0.075000\n",
      "25%        0.525000\n",
      "50%        0.525000\n",
      "75%        0.565000\n",
      "max        0.585000\n",
      "Name: mid_price, dtype: float64\n",
      "\n",
      "Matched rows — mid_price distribution:\n",
      "count    38639.000000\n",
      "mean         0.356192\n",
      "std          0.172974\n",
      "min          0.005000\n",
      "25%          0.175000\n",
      "50%          0.425000\n",
      "75%          0.485000\n",
      "max          0.605000\n",
      "Name: mid_price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Isolate the mismatched population\n",
    "import numpy as np\n",
    "\n",
    "idx     = np.searchsorted(live_ts_arr, hist_ts_arr)\n",
    "idx     = np.clip(idx, 0, len(live_ts_arr) - 1)\n",
    "offsets = np.abs(hist_ts_arr - live_ts_arr[idx])\n",
    "\n",
    "# Split into matched vs unmatched\n",
    "threshold = 5  # ms\n",
    "matched   = hist_up[offsets <= threshold].copy()\n",
    "unmatched = hist_up[offsets >  threshold].copy()\n",
    "unmatched[\"offset_ms\"] = offsets[offsets > threshold]\n",
    "\n",
    "print(f\"Matched   : {len(matched):,}  ({len(matched)/len(hist_up):.1%})\")\n",
    "print(f\"Unmatched : {len(unmatched):,}  ({len(unmatched)/len(hist_up):.1%})\")\n",
    "\n",
    "# Where in the market window do unmatched rows cluster?\n",
    "# Extract market open timestamp from slug\n",
    "slug_ts   = int(slug.split(\"-\")[-1]) * 1000  # slug unix seconds → ms\n",
    "market_end = slug_ts + 300_000\n",
    "\n",
    "unmatched[\"seconds_into_market\"] = (unmatched[\"exchange_timestamp\"] - slug_ts) / 1000\n",
    "print(\"\\nUnmatched rows — position in market window (seconds):\")\n",
    "print(unmatched[\"seconds_into_market\"].describe())\n",
    "\n",
    "# Are they clustered at specific times, or spread evenly?\n",
    "print(\"\\nDistribution across 30s buckets:\")\n",
    "bins = pd.cut(unmatched[\"seconds_into_market\"], bins=10)\n",
    "print(unmatched.groupby(bins, observed=True).size())\n",
    "\n",
    "# What do the unmatched rows look like — are they distinct price levels?\n",
    "print(\"\\nUnmatched rows — mid_price distribution:\")\n",
    "print(unmatched[\"mid_price\"].describe())\n",
    "print(\"\\nMatched rows — mid_price distribution:\")\n",
    "print(matched[\"mid_price\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a86a8832-ab3c-42e9-a728-799d6c70364f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 1585 slugs...\n",
      "\n",
      "  btc-updown-5m-1771350900: ERROR — Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "  btc-updown-5m-1771351500: ERROR — Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "  btc-updown-5m-1771352100: ERROR — Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "                    slug  hist_rows  live_rows  match_rate  unmatched_mean_sec  unmatched_p75_sec\n",
      "btc-updown-5m-1771346400      34798       2653    0.027042          108.745437          166.45700\n",
      "btc-updown-5m-1771346700      49828      67877    0.746026           34.206882           50.77750\n",
      "btc-updown-5m-1771347000      43046      82484    0.993100            1.894572            2.49400\n",
      "btc-updown-5m-1771347300      32112      31641    0.460980           57.579564           88.14300\n",
      "btc-updown-5m-1771347600      49659      91692    0.991119            3.114052            3.17100\n",
      "btc-updown-5m-1771347900      36369      29056    0.407435           78.918891          117.63900\n",
      "btc-updown-5m-1771348200      15379      27282    0.979583            2.401685            3.29575\n",
      "btc-updown-5m-1771348500      46380      62178    0.743316           31.576293           46.66400\n",
      "btc-updown-5m-1771348800      39170      73639    0.986444            3.311881            3.95300\n",
      "btc-updown-5m-1771349100      34255      50869    0.819092           18.457404           27.12500\n",
      "btc-updown-5m-1771349400      28281      43090    0.815777           18.756682           26.52600\n",
      "btc-updown-5m-1771350000      29169        996    0.010251          107.601270          162.59675\n",
      "btc-updown-5m-1771350300      47886      90690    0.995113            2.611803            1.50700\n",
      "btc-updown-5m-1771350600      48679      38725    0.365044           91.605441          139.55600\n",
      "btc-updown-5m-1771351200      49352      94338    0.996758            1.628869            2.15225\n",
      "btc-updown-5m-1771351800      42748      81014    0.994830            1.762303            2.22400\n",
      "btc-updown-5m-1771352400      18084      33513    0.987226            2.469381            2.30850\n",
      "\n",
      "Median match rate : 81.9%\n",
      "Median unmatched mean position : 18.5s into market\n",
      "Median unmatched p75 position  : 26.5s into market\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "LIVE_BOOK_DIR  = Path(\"data/book_snapshots\")\n",
    "LIVE_TRADE_DIR = Path(\"data/trade_events\")\n",
    "HIST_DIR       = Path(\"data/telonex_book_snapshots\")\n",
    "\n",
    "live_slugs = {p.stem for p in LIVE_BOOK_DIR.glob(\"btc-updown-5m-*.parquet\")}\n",
    "hist_slugs = {p.stem for p in HIST_DIR.glob(\"btc-updown-5m-*.parquet\")}\n",
    "common = sorted(live_slugs & hist_slugs)\n",
    "\n",
    "print(f\"Checking {len(common)} slugs...\\n\")\n",
    "\n",
    "results = []\n",
    "for slug in common[:20]:  # sample 20\n",
    "    try:\n",
    "        books  = pd.read_parquet(LIVE_BOOK_DIR  / f\"{slug}.parquet\")\n",
    "        trades = pd.read_parquet(LIVE_TRADE_DIR / f\"{slug}.parquet\") \\\n",
    "                 if (LIVE_TRADE_DIR / f\"{slug}.parquet\").exists() else pd.DataFrame()\n",
    "        hist   = pd.read_parquet(HIST_DIR / f\"{slug}.parquet\")\n",
    "\n",
    "        slug_ts   = int(slug.split(\"-\")[-1]) * 1000\n",
    "        up_asset  = hist[hist[\"token_label\"] == \"Up\"][\"asset_id\"].iloc[0]\n",
    "        hist_up   = hist[hist[\"token_label\"] == \"Up\"].sort_values(\"exchange_timestamp\")\n",
    "\n",
    "        live_ts = np.sort(pd.concat([\n",
    "            books[books[\"asset_id\"] == up_asset][[\"exchange_timestamp\"]],\n",
    "            trades[trades[\"asset_id\"] == up_asset][[\"exchange_timestamp\"]] if not trades.empty else pd.DataFrame(columns=[\"exchange_timestamp\"]),\n",
    "        ])[\"exchange_timestamp\"].values)\n",
    "\n",
    "        hist_ts = hist_up[\"exchange_timestamp\"].values\n",
    "        idx     = np.clip(np.searchsorted(live_ts, hist_ts), 0, len(live_ts) - 1)\n",
    "        offsets = np.abs(hist_ts - live_ts[idx]) if len(live_ts) else hist_ts\n",
    "\n",
    "        unmatched_mask = offsets > 5\n",
    "        unmatched_secs = (hist_ts[unmatched_mask] - slug_ts) / 1000\n",
    "\n",
    "        results.append({\n",
    "            \"slug\":               slug,\n",
    "            \"hist_rows\":          len(hist_up),\n",
    "            \"live_rows\":          len(live_ts),\n",
    "            \"match_rate\":         (~unmatched_mask).mean(),\n",
    "            \"unmatched_mean_sec\": unmatched_secs.mean() if len(unmatched_secs) else np.nan,\n",
    "            \"unmatched_p75_sec\":  np.percentile(unmatched_secs, 75) if len(unmatched_secs) else np.nan,\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"  {slug}: ERROR — {e}\")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\nMedian match rate : {df['match_rate'].median():.1%}\")\n",
    "print(f\"Median unmatched mean position : {df['unmatched_mean_sec'].median():.1f}s into market\")\n",
    "print(f\"Median unmatched p75 position  : {df['unmatched_p75_sec'].median():.1f}s into market\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cec10383-466e-4ce8-8ad0-4ba5d161bb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Live bid_size_1 distribution:\n",
      "count      8890.000000\n",
      "mean       4221.360717\n",
      "std       41770.377153\n",
      "min           0.000000\n",
      "25%          39.872500\n",
      "50%         111.700000\n",
      "75%         232.000000\n",
      "max      523770.780000\n",
      "Name: bid_size_1, dtype: float64\n",
      "\n",
      "Telonex bid_size_1 distribution (Up token):\n",
      "count    39170.000000\n",
      "mean       217.859717\n",
      "std        691.042554\n",
      "min          0.000000\n",
      "25%         29.000000\n",
      "50%         84.880000\n",
      "75%        187.280000\n",
      "max      15075.840000\n",
      "Name: bid_size_1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "slug  = \"btc-updown-5m-1771348800\"\n",
    "books = pd.read_parquet(f\"data/book_snapshots/{slug}.parquet\")\n",
    "hist  = pd.read_parquet(f\"data/telonex_book_snapshots/{slug}.parquet\")\n",
    "\n",
    "# Compare raw size magnitudes\n",
    "print(\"Live bid_size_1 distribution:\")\n",
    "print(books[\"bid_size_1\"].describe())\n",
    "\n",
    "print(\"\\nTelonex bid_size_1 distribution (Up token):\")\n",
    "print(hist[hist[\"token_label\"]==\"Up\"][\"bid_size_1\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "705d994b-7733-41ef-9db0-7e932ac3cf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Live bid_size_1 — excluding top 1%:\n",
      "count     8801.000000\n",
      "mean       619.597051\n",
      "std       2800.121926\n",
      "min          0.000000\n",
      "25%         39.210000\n",
      "50%        110.300000\n",
      "75%        225.240000\n",
      "max      28301.710000\n",
      "Name: bid_size_1, dtype: float64\n",
      "  p99=28303.9,  p99.9=522275.4,  max=523770.8\n",
      "\n",
      "Telonex bid_size_1 — excluding top 1%:\n",
      "count    38784.000000\n",
      "mean       172.782335\n",
      "std        327.045785\n",
      "min          0.000000\n",
      "25%         28.660000\n",
      "50%         82.120000\n",
      "75%        183.000000\n",
      "max       2522.160000\n",
      "Name: bid_size_1, dtype: float64\n",
      "  p99=2522.2,  p99.9=14010.1,  max=15075.8\n",
      "\n",
      "Live rows with bid_size_1 > 10,000: 273\n",
      "     exchange_timestamp  bid_size_1  bid_price_1  mid_price\n",
      "44        1771348805272   523770.78         0.99      0.495\n",
      "46        1771348805321   523759.20         0.99      0.495\n",
      "98        1771348806025   523599.20         0.99      0.495\n",
      "134       1771348806778   522553.49         0.99      0.495\n",
      "156       1771348807090   522376.22         0.99      0.495\n",
      "160       1771348807142   522313.07         0.99      0.495\n",
      "192       1771348807849   522310.49         0.99      0.495\n",
      "270       1771348809039   522288.91         0.99      0.495\n",
      "278       1771348809341   522281.52         0.99      0.495\n",
      "319       1771348809799   522274.63         0.99      0.495\n",
      "\n",
      "Time between large-size rows (ms):\n",
      "count       272.000000\n",
      "mean       1100.187500\n",
      "std        8671.094391\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%          94.500000\n",
      "75%         496.000000\n",
      "max      140366.000000\n",
      "Name: exchange_timestamp, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "slug  = \"btc-updown-5m-1771348800\"\n",
    "books = pd.read_parquet(f\"data/book_snapshots/{slug}.parquet\")\n",
    "hist  = pd.read_parquet(f\"data/telonex_book_snapshots/{slug}.parquet\")\n",
    "hist_up = hist[hist[\"token_label\"] == \"Up\"]\n",
    "\n",
    "# Look at the full size distribution excluding outliers\n",
    "import numpy as np\n",
    "\n",
    "for label, sizes in [(\"Live\", books[\"bid_size_1\"]), (\"Telonex\", hist_up[\"bid_size_1\"])]:\n",
    "    p99 = sizes.quantile(0.99)\n",
    "    print(f\"{label} bid_size_1 — excluding top 1%:\")\n",
    "    print(sizes[sizes <= p99].describe())\n",
    "    print(f\"  p99={p99:.1f},  p99.9={sizes.quantile(0.999):.1f},  max={sizes.max():.1f}\\n\")\n",
    "\n",
    "# Are the giant live values transient (appear once) or persistent?\n",
    "large_live = books[books[\"bid_size_1\"] > 10000].sort_values(\"exchange_timestamp\")\n",
    "print(f\"Live rows with bid_size_1 > 10,000: {len(large_live)}\")\n",
    "if len(large_live):\n",
    "    print(large_live[[\"exchange_timestamp\", \"bid_size_1\", \"bid_price_1\", \"mid_price\"]].head(10))\n",
    "    # Check if consecutive — are they persistent orders or one-off spikes?\n",
    "    ts_diffs = large_live[\"exchange_timestamp\"].diff()\n",
    "    print(f\"\\nTime between large-size rows (ms):\")\n",
    "    print(ts_diffs.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe27885a-f169-4407-9e4e-b74fc854fc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large bid_size_1 rows — all bid levels:\n",
      "    bid_price_1  bid_price_2  bid_price_3  bid_price_4  bid_price_5  bid_price_6  bid_price_7  bid_price_8  bid_price_9  bid_price_10  bid_size_1  bid_size_2  bid_size_3  bid_size_4  bid_size_5  bid_size_6  bid_size_7  bid_size_8  bid_size_9  bid_size_10\n",
      "44         0.99         0.98         0.97         0.96         0.95         0.94         0.93         0.92         0.91           0.9   523770.78     21923.0    10209.74     17832.8    24020.04     8575.32    23669.77    20646.98    14543.88     11389.98\n",
      "46         0.99         0.98         0.97         0.96         0.95         0.94         0.93         0.92         0.91           0.9   523759.20     21923.0    10209.74     17832.8    24020.04     8575.32    23669.77    20646.98    14543.88     11389.98\n",
      "98         0.99         0.98         0.97         0.96         0.95         0.94         0.93         0.92         0.91           0.9   523599.20     21923.0    10209.74     17832.8    24020.04     8575.32    23669.77    20646.98    14543.88     11389.98\n",
      "\n",
      "Bid price distributions across levels:\n",
      "  bid_price_1: mean=0.4930, min=0.0000, max=0.9990\n",
      "  bid_price_2: mean=0.4833, min=0.0000, max=0.9910\n",
      "  bid_price_3: mean=0.4736, min=0.0000, max=0.9900\n",
      "  bid_price_4: mean=0.4641, min=0.0000, max=0.9800\n",
      "  bid_price_5: mean=0.4546, min=0.0000, max=0.9700\n",
      "\n",
      "Normal rows bid_price_1: mean=0.4783, max=0.9900\n",
      "Large rows  bid_price_1: mean=0.9581, min=0.0100\n"
     ]
    }
   ],
   "source": [
    "slug  = \"btc-updown-5m-1771348800\"\n",
    "books = pd.read_parquet(f\"data/book_snapshots/{slug}.parquet\")\n",
    "\n",
    "# Look at all 10 bid levels for the large-size rows\n",
    "large = books[books[\"bid_size_1\"] > 10000].copy()\n",
    "\n",
    "bid_price_cols = [f\"bid_price_{i}\" for i in range(1, 11)]\n",
    "bid_size_cols  = [f\"bid_size_{i}\"  for i in range(1, 11)]\n",
    "\n",
    "print(\"Large bid_size_1 rows — all bid levels:\")\n",
    "print(large[bid_price_cols + bid_size_cols].head(3).to_string())\n",
    "\n",
    "# Also check: is the 0.99 bid always level 1, or does it appear at other levels?\n",
    "print(\"\\nBid price distributions across levels:\")\n",
    "for i in range(1, 6):\n",
    "    col = f\"bid_price_{i}\"\n",
    "    print(f\"  {col}: mean={books[col].mean():.4f}, \"\n",
    "          f\"min={books[col].min():.4f}, max={books[col].max():.4f}\")\n",
    "\n",
    "# What does the normal book look like vs the large-size rows?\n",
    "normal = books[books[\"bid_size_1\"] <= 10000]\n",
    "print(f\"\\nNormal rows bid_price_1: mean={normal['bid_price_1'].mean():.4f}, \"\n",
    "      f\"max={normal['bid_price_1'].max():.4f}\")\n",
    "print(f\"Large rows  bid_price_1: mean={large['bid_price_1'].mean():.4f}, \"\n",
    "      f\"min={large['bid_price_1'].min():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a3f134-b20c-48b1-97e9-5abfb1009b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
